{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1747655573598,"user":{"displayName":"Nero Li","userId":"16312290114531733443"},"user_tz":-60},"id":"ayfGcV5GNRMT","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bd987ffd-1802-4a54-e96f-2b306d93ed03"},"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /content/gis_utils.py\n"]}],"source":["%%writefile /content/gis_utils.py\n","import geopandas as gpd\n","import numpy as np\n","from shapely.geometry import box\n","from pyproj import Transformer\n","from tqdm import tqdm\n","from scipy.stats import zscore\n","\n","def get_file_paths(city_name):\n","    base_path = f\"data/{city_name}-share_data\"\n","    codes = {\"NY\":225,\"SF\":233,\"Chicago\":97}\n","    c = codes.get(city_name)\n","    if c is None:\n","        raise ValueError(f\"Unsupported city: {city_name}\")\n","    return {\n","        \"population\": f\"{base_path}/{city_name}_zone_{c}_population.shp\",\n","        \"pois\":       f\"{base_path}/{city_name}_pois.shp\",\n","        \"road_network\":f\"{base_path}/{city_name}_roadnetwork.pkl\",\n","        \"accidents\":  f\"{base_path}/{city_name}_crash_information.csv\",\n","        \"demand\":     f\"{base_path}/{city_name}-taxi_zone.npy\",\n","        \"save_path\":  f\"{base_path}/processed\"\n","    }\n","\n","def transform_network_coordinates(G, from_crs=\"EPSG:4326\", to_crs=\"EPSG:3395\"):\n","    transformer = Transformer.from_crs(from_crs, to_crs, always_xy=True)\n","    for node,data in tqdm(G.nodes(data=True), desc=\"Transforming Network Coordinates\"):\n","        if \"x\" in data and \"y\" in data:\n","            data[\"x\"], data[\"y\"] = transformer.transform(data[\"x\"], data[\"y\"])\n","\n","def compute_population_density(area, pop_gdf):\n","    polys = pop_gdf[pop_gdf.intersects(area)]\n","    if polys.empty: return 0\n","    polys = polys.copy()\n","    polys[\"overlap_area\"] = polys.geometry.intersection(area).area / 1e6\n","    polys[\"ratio\"] = polys[\"overlap_area\"] / polys[\"area_km2\"]\n","    polys[\"pop_catch\"] = polys[\"population\"] * polys[\"ratio\"]\n","    total = polys[\"pop_catch\"].sum()\n","    return total / (area.area / 1e6)\n","\n","def extract_road_network_subgraph(area, nodes_gdf, G):\n","    ids = nodes_gdf[nodes_gdf.within(area)][\"node\"].values\n","    return G.subgraph(ids).copy()\n","\n","def compute_poi_densities(area, pois_gdf, categories):\n","    sub = pois_gdf[pois_gdf.within(area)]\n","    area_km2 = area.area / 1e6\n","    return [ sub[sub[\"category\"]==cat].shape[0] / area_km2 for cat in categories ]\n","\n","def generate_random_points_within_polygon(poly, n):\n","    minx,miny,maxx,maxy = poly.bounds\n","    factor = 5\n","    xs = np.random.uniform(minx, maxx, n*factor)\n","    ys = np.random.uniform(miny, maxy, n*factor)\n","    pts = gpd.GeoSeries(gpd.points_from_xy(xs, ys), crs=\"EPSG:3395\")\n","    pts = pts[pts.within(poly)]\n","    if len(pts) < n:\n","        return generate_random_points_within_polygon(poly, n)\n","    return pts.iloc[:n].tolist()\n","\n","def compute_accident_counts(area, acc_gdf):\n","    sub = acc_gdf[acc_gdf.within(area)]\n","    total = len(sub)\n","    sev = sub[\"Severity\"].value_counts().to_dict()\n","    return [ total, sev.get(1,0), sev.get(2,0), sev.get(3,0), sev.get(4,0) ]\n","\n","def compute_demand(area, pop_gdf, demand_arr):\n","    center = area.centroid\n","    match = pop_gdf[pop_gdf.contains(center)]\n","    if not match.empty:\n","        return demand_arr[match.index[0]]\n","    return np.zeros((24,4))\n","\n","def construct_features(n, ny_population, ny_pois, nodes_gdf, ny_road_network,\n","                       categories, accident_data_gdf, demand_data, side_length=2000):\n","    city_poly = ny_population.unary_union\n","    pts = generate_random_points_within_polygon(city_poly, n)\n","    catchments = [\n","        box(p.x - side_length/2, p.y - side_length/2,\n","            p.x + side_length/2, p.y + side_length/2)\n","        for p in pts\n","    ]\n","    std_dem = zscore(demand_data, axis=None)\n","    feat_pop, subGs, feat_pois, feats_acc, feats_dem = [], [], [], [], []\n","    for area in tqdm(catchments, desc=\"Processing Catchments\"):\n","        feat_pop.append(compute_population_density(area, ny_population))\n","        subGs.append(extract_road_network_subgraph(area, nodes_gdf, ny_road_network))\n","        feat_pois.append(compute_poi_densities(area, ny_pois, categories))\n","        feats_acc.append(compute_accident_counts(area, accident_data_gdf))\n","        feats_dem.append(compute_demand(area, ny_population, std_dem))\n","    return feat_pop, subGs, feat_pois, feats_acc, feats_dem\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"-7b3IR4eNe7s","executionInfo":{"status":"ok","timestamp":1747655576868,"user_tz":-60,"elapsed":905,"user":{"displayName":"Nero Li","userId":"16312290114531733443"}}},"outputs":[],"source":["import gis_utils\n","from gis_utils import get_file_paths, construct_features\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1747655577650,"user":{"displayName":"Nero Li","userId":"16312290114531733443"},"user_tz":-60},"id":"Kr9usVPZON8d","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f892c203-042b-447b-e792-5191d74557a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting gis_processing.py\n"]}],"source":["%%writefile gis_processing.py\n","\n","import pandas as pd\n","import geopandas as gpd\n","import argparse\n","import numpy as np\n","import pickle\n","from gis_utils import (get_file_paths, transform_network_coordinates, construct_features)\n","\n","def main():\n","    parser = argparse.ArgumentParser(\n","        description=\"Process datasets for population, POIs, and road-network analysis.\"\n","    )\n","    parser.add_argument(\n","        \"--city\",\n","        type=str,\n","        default=\"Chicago\",\n","        choices=[\"NY\", \"SF\", \"Chicago\"],\n","        help=\"City name to process (default: Chicago).\"\n","    )\n","    parser.add_argument(\n","        \"--num_catchment\",\n","        type=int,\n","        default=50,\n","        help=\"Number of random catchment areas.\"\n","    )\n","    parser.add_argument(\n","        \"--side_length\",\n","        type=int,\n","        default=2000,\n","        help=\"Side length of each catchment area in meters.\"\n","    )\n","    args = parser.parse_args()\n","\n","    # ------------------------------------------------------------------\n","    # Get all file paths for the chosen city\n","    # ------------------------------------------------------------------\n","    file_paths = get_file_paths(args.city)\n","\n","    # Step 1 ── Load population data\n","    print(f\"Loading population data for {args.city}…\")\n","    population = gpd.read_file(file_paths[\"population\"])\n","    population = population.to_crs(epsg=3395)\n","    population[\"area_km2\"] = population.geometry.area / 1e6\n","    population[\"pop_den\"]  = population[\"population\"] / population[\"area_km2\"]\n","    print(\"Population data loaded. Total zones:\", len(population))\n","\n","    # Step 2 ── Load points-of-interest (POI) data\n","    print(f\"Loading POI data for {args.city}…\")\n","    pois = gpd.read_file(file_paths[\"pois\"])\n","    pois = pois.to_crs(epsg=3395)\n","    print(\"POI data loaded. Total points:\", len(pois))\n","\n","    # Step 3 ── Load the road-network graph\n","    print(f\"Loading road-network data for {args.city}…\")\n","    with open(file_paths[\"road_network\"], \"rb\") as f:\n","        road_network = pickle.load(f)\n","    print(\n","        \"Road-network data loaded. \"\n","        \"Total nodes:\", road_network.number_of_nodes(),\n","        \"Total edges:\", road_network.number_of_edges()\n","    )\n","\n","    # Step 4 ── Re-project the road network to EPSG 3395\n","    print(\"Transforming road-network coordinates to EPSG:3395…\")\n","    transform_network_coordinates(\n","        road_network,\n","        from_crs=\"EPSG:4326\",\n","        to_crs=\"EPSG:3395\"\n","    )\n","    print(\"Coordinate transformation complete.\")\n","\n","    # Step 5 ── Build a GeoDataFrame for road-network nodes\n","    nodes_data = dict(road_network.nodes(data=True))\n","    nodes_df = pd.DataFrame.from_dict(nodes_data, orient=\"index\")\n","    nodes_df[\"node\"] = nodes_df.index\n","    nodes_gdf = gpd.GeoDataFrame(\n","        nodes_df,\n","        geometry=gpd.points_from_xy(nodes_df.x, nodes_df.y),\n","        crs=population.crs\n","    )\n","\n","    # Step 6 ── Define POI categories to aggregate\n","    categories = [\n","        \"office_tags\", \"sustenance_tags\", \"transportation_tags\",\n","        \"retail_tags\", \"leisure_tags\", \"residence_tags\"\n","    ]\n","\n","    # Step 7 ── Load traffic-accident data\n","    print(f\"Loading accident data for {args.city}…\")\n","    accident_data = pd.read_csv(file_paths[\"accidents\"])\n","    accident_data[\"Start_Lat\"] = pd.to_numeric(accident_data[\"Start_Lat\"], errors=\"coerce\")\n","    accident_data[\"Start_Lng\"] = pd.to_numeric(accident_data[\"Start_Lng\"], errors=\"coerce\")\n","    accident_data = accident_data.dropna(subset=[\"Start_Lat\", \"Start_Lng\"])\n","    accident_data_gdf = gpd.GeoDataFrame(\n","        accident_data,\n","        geometry=gpd.points_from_xy(accident_data.Start_Lng, accident_data.Start_Lat),\n","        crs=\"EPSG:4326\"\n","    ).to_crs(epsg=3395)\n","    print(\"Accident data loaded. Total accidents:\", len(accident_data_gdf))\n","\n","    # Step 8 ── Load ride-demand data\n","    print(\"Loading demand data…\")\n","    demand_data = np.load(file_paths[\"demand\"], allow_pickle=True)\n","    print(\"Demand data loaded. Shape:\", demand_data.shape)\n","\n","    # Step 9 ── Generate features for random catchment areas\n","    print(f\"Generating features for {args.num_catchment} random locations…\")\n","    (\n","        feat_pop_list,\n","        sub_graph_list,\n","        feat_pois_list,\n","        target_accident_list,\n","        demand_list\n","    ) = construct_features(\n","        n=args.num_catchment,\n","        ny_population=population,\n","        ny_pois=pois,\n","        nodes_gdf=nodes_gdf,\n","        ny_road_network=road_network,\n","        categories=categories,\n","        accident_data_gdf=accident_data_gdf,\n","        demand_data=demand_data,\n","        side_length=args.side_length\n","    )\n","    print(\"Feature generation complete.\")\n","\n","    # Step 10 ── Persist results to disk\n","    save_path = file_paths[\"save_path\"]\n","\n","    data = pd.DataFrame({\n","        \"population_density\": feat_pop_list,\n","        \"poi_densities\"     : feat_pois_list,\n","        \"accident_counts\"   : target_accident_list,\n","    })\n","\n","    # Split nested columns into flat tables\n","    poi_densities_df = pd.DataFrame(data[\"poi_densities\"].tolist(), columns=categories)\n","    accident_counts_df = pd.DataFrame(\n","        data[\"accident_counts\"].tolist(),\n","        columns=[\"total_accidents\", \"severity_1\", \"severity_2\", \"severity_3\", \"severity_4\"]\n","    )\n","    data_output = pd.concat(\n","        [\n","            data.drop([\"poi_densities\", \"accident_counts\"], axis=1),\n","            poi_densities_df,\n","            accident_counts_df\n","        ],\n","        axis=1\n","    )\n","    data_output.to_csv(f\"{save_path}/feature_data.csv\", index=False)\n","    print(f\"Feature data saved to {save_path}/feature_data.csv.\")\n","\n","    demand_array = np.stack(demand_list, axis=0)\n","    np.save(f\"{save_path}/demand_features.npy\", demand_array)\n","    print(f\"Demand features saved to {save_path}/demand_features.npy.\")\n","\n","    with open(f\"{save_path}/sub_graph_list.pkl\", \"wb\") as f:\n","        pickle.dump(sub_graph_list, f)\n","    print(f\"Subgraph list saved to {save_path}/sub_graph_list.pkl.\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":47,"status":"ok","timestamp":1747655580618,"user":{"displayName":"Nero Li","userId":"16312290114531733443"},"user_tz":-60},"id":"XVBmbx04O5ym","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b3f1003c-9f0b-4ad7-b3d5-a5e39431a3de"},"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting 2-generate_graph_data_homo.py\n"]}],"source":["%%writefile 2-generate_graph_data_homo.py\n","import argparse\n","import torch\n","from torch_geometric.data import Data\n","from torch_geometric.utils import from_networkx\n","from sklearn.preprocessing import StandardScaler\n","import numpy as np\n","from tqdm import tqdm\n","import pandas as pd\n","import pickle\n","import os\n","\n","def main():\n","    parser = argparse.ArgumentParser(\n","        description=\"Generate homogeneous PyG Data objects from city-specific datasets.\"\n","    )\n","    parser.add_argument(\n","        \"--city\",\n","        type=str,\n","        default=\"Chicago\",\n","        choices=[\"NY\", \"SF\", \"Chicago\"],\n","        help=\"City name to process (default: Chicago).\"\n","    )\n","    args = parser.parse_args()\n","\n","    # ------------------------------------------------------------------\n","    # Utility helpers: resolve I/O paths for the chosen city\n","    # ------------------------------------------------------------------\n","    def get_paths_by_city(city_name):\n","        \"\"\"Return paths to feature CSV, sub-graph list and demand tensor.\"\"\"\n","        base_path = f\"data/{city_name}-share_data/processed\"\n","        return {\n","            \"feature_data_path\"   : f\"{base_path}/feature_data.csv\",\n","            \"sub_graph_list_path\" : f\"{base_path}/sub_graph_list.pkl\",\n","            \"demand_data_path\"    : f\"{base_path}/demand_features.npy\"  #  shape (N, 24, 4)\n","        }\n","\n","    def get_data_list_save_path(city_name):\n","        base_path = f\"data/{city_name}-share_data/processed\"\n","        return f\"{base_path}/data_list.pt\"\n","\n","    # Resolve all paths\n","    paths              = get_paths_by_city(args.city)\n","    feature_data_path  = paths[\"feature_data_path\"]\n","    sub_graph_list_path = paths[\"sub_graph_list_path\"]\n","    demand_data_path   = paths[\"demand_data_path\"]\n","    data_list_path     = get_data_list_save_path(args.city)\n","\n","    # ------------------------------------------------------------------\n","    # 1)  Load tabular feature data\n","    # ------------------------------------------------------------------\n","    data = pd.read_csv(feature_data_path)\n","    print(f\"Feature table loaded from '{feature_data_path}'.\")\n","\n","    # ------------------------------------------------------------------\n","    # 2)  Load sub-graph list (road-network ego-graphs)\n","    # ------------------------------------------------------------------\n","    with open(sub_graph_list_path, \"rb\") as f:\n","        sub_graph_list = pickle.load(f)\n","    print(f\"Sub-graph list loaded from '{sub_graph_list_path}'.\")\n","\n","    # ------------------------------------------------------------------\n","    # 3)  Load demand tensor  (N, 24, 4)\n","    # ------------------------------------------------------------------\n","    demand_data = np.load(demand_data_path)    # (N, 24, 4)\n","    print(f\"Demand tensor loaded from '{demand_data_path}', shape: {demand_data.shape}\")\n","\n","    # ------------------------------------------------------------------\n","    # 4)  Assemble input features\n","    # ------------------------------------------------------------------\n","    categories = [\n","        \"office_tags\", \"sustenance_tags\", \"transportation_tags\",\n","        \"retail_tags\", \"leisure_tags\", \"residence_tags\"\n","    ]\n","    pois = data[categories].values\n","\n","    # ------------------------------------------------------------------\n","    # 5)  Target variables (traffic-accident statistics)\n","    # ------------------------------------------------------------------\n","    accident_columns = [\n","        \"total_accidents\", \"severity_1\", \"severity_2\", \"severity_3\", \"severity_4\"\n","    ]\n","    accidents = data[accident_columns].values\n","\n","    # ------------------------------------------------------------------\n","    # 6)  Standardise numerical features\n","    # ------------------------------------------------------------------\n","    pois_scaled      = StandardScaler().fit_transform(pois)\n","    accidents_scaled = StandardScaler().fit_transform(accidents)\n","\n","    # ------------------------------------------------------------------\n","    # 7)  Clean node/edge attributes inside each sub-graph\n","    # ------------------------------------------------------------------\n","    node_types = set()\n","    for g in sub_graph_list:\n","        for node, attrs in g.nodes(data=True):\n","            node_type = attrs.get(\"highway\", \"intersection\")\n","            attrs[\"type\"] = node_type\n","            attrs.pop(\"highway\", None)\n","            attrs.pop(\"ref\", None)\n","            node_types.add(node_type)\n","\n","    node_type_to_id = {t: i for i, t in enumerate(sorted(node_types))}\n","    num_node_types  = len(node_type_to_id)\n","    print(f\"Detected {num_node_types} unique node types.\")\n","\n","    for g in sub_graph_list:\n","        # Node attributes\n","        for node, attrs in g.nodes(data=True):\n","            attrs[\"type_id\"] = node_type_to_id[attrs[\"type\"]]\n","        # Edge attributes: keep only highway / maxspeed\n","        for _, _, attrs in g.edges(data=True):\n","            for k in list(attrs.keys()):\n","                if k not in [\"highway\", \"maxspeed\"]:\n","                    del attrs[k]\n","            attrs.setdefault(\"highway\", \"unknown\")\n","            attrs.setdefault(\"maxspeed\", 20)\n","\n","    # ------------------------------------------------------------------\n","    # 8)  Helper: convert a single NetworkX graph → PyG Data\n","    # ------------------------------------------------------------------\n","    def convert_to_pyg_data(sub_graph, poi, accident, demand, is_homogeneous=True):\n","        \"\"\"Convert one sub-graph plus its tabular features into a PyG Data object.\"\"\"\n","        if sub_graph.number_of_nodes() == 0:\n","            return None\n","\n","        sub_graph = sub_graph.copy()\n","\n","        # Ensure every node has a numeric type_id and drop other attributes\n","        for n in sub_graph.nodes:\n","            attrs = sub_graph.nodes[n]\n","            attrs.setdefault(\"type_id\", node_type_to_id.get(\"unknown\", 0))\n","            for k in list(attrs.keys()):\n","                if k not in [\"type_id\"]:\n","                    del attrs[k]\n","\n","        # Drop edge attributes if a homogeneous graph is required\n","        if is_homogeneous:\n","            for _, _, d in sub_graph.edges(data=True):\n","                d.clear()\n","\n","        data = from_networkx(sub_graph)\n","\n","        # One-hot node feature matrix\n","        type_ids = torch.tensor(\n","            [attr[\"type_id\"] for _, attr in sub_graph.nodes(data=True)],\n","            dtype=torch.long\n","        )\n","        data.x = torch.nn.functional.one_hot(type_ids, num_classes=num_node_types).float()\n","\n","        # Remove leftover keys except x / edge_index\n","        for k in set(data.keys()) - {\"x\", \"edge_index\"}:\n","            del data[k]\n","\n","        # Attach graph-level attributes\n","        data.poi      = torch.tensor(poi,      dtype=torch.float).unsqueeze(0)\n","        data.accident = torch.tensor(accident, dtype=torch.float).unsqueeze(0)\n","        data.demand   = torch.tensor(demand,   dtype=torch.float).unsqueeze(0)\n","\n","        return data\n","\n","    # ------------------------------------------------------------------\n","    # 9)  Build the full list of Data objects\n","    # ------------------------------------------------------------------\n","    data_list          = []\n","    num_skipped_graphs = 0\n","\n","    for i in tqdm(range(len(sub_graph_list)), desc=\"Converting to PyG Data\"):\n","        sub_graph = sub_graph_list[i]\n","        poi       = pois_scaled[i]       # (6,)\n","        accident  = accidents_scaled[i]  # (5,)\n","        demand    = demand_data[i]       # (24, 4)\n","\n","        graph_data = convert_to_pyg_data(\n","            sub_graph, poi, accident, demand, is_homogeneous=True\n","        )\n","        if graph_data is None:\n","            num_skipped_graphs += 1\n","            continue\n","        data_list.append(graph_data)\n","\n","    print(\n","        f\"Converted {len(data_list)} sub-graphs; \"\n","        f\"skipped {num_skipped_graphs} empty graphs.\"\n","    )\n","\n","    # ------------------------------------------------------------------\n","    # 10)  Persist the list to disk\n","    # ------------------------------------------------------------------\n","    os.makedirs(os.path.dirname(data_list_path), exist_ok=True)\n","    torch.save(data_list, data_list_path)\n","    print(f\"PyG Data list saved to '{data_list_path}'.\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"code","source":["# If DIG (required for GraphCL) is not installed, uncomment the next line:\n","# !pip install dive-into-graphs -q\n","\n","# Pull the latest PyG code from the main repository and install\n","!pip install git+https://github.com/pyg-team/pytorch_geometric.git\n","\n","!pip install --no-index --upgrade torch-scatter torch-sparse torch-cluster pyg-lib \\\n","  --find-links https://data.pyg.org/whl/torch-$(python -c \"import torch; print(torch.__version__.split('+')[0])\")+cpu.html\n","\n","# Install PyG core and its extensions compatible with the current Torch version (CPU build)\n","!pip install --no-index --upgrade torch-geometric torch-scatter torch-sparse \\\n","  --find-links https://data.pyg.org/whl/torch-$(python -c \"import torch; print(torch.__version__.split('+')[0])\")+cpu.html\n","\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jYZ-GuSkvmRy","executionInfo":{"status":"ok","timestamp":1747655598669,"user_tz":-60,"elapsed":14481,"user":{"displayName":"Nero Li","userId":"16312290114531733443"}},"outputId":"d95210c9-8da6-4843-e440-0c8750e4251e"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n","  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-16cwk5ov\n","  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-16cwk5ov\n","  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit ea74852394618f8f29377c7605b2b673783ca881\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (3.11.15)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (2025.3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (3.1.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (2.0.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (3.2.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (3.5.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.20.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric==2.7.0) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (2025.4.26)\n","Looking in links: https://data.pyg.org/whl/torch-2.6.0+cpu.html\n","Requirement already satisfied: torch-scatter in /usr/local/lib/python3.11/dist-packages (2.1.2+pt26cpu)\n","Requirement already satisfied: torch-sparse in /usr/local/lib/python3.11/dist-packages (0.6.18+pt26cpu)\n","Requirement already satisfied: torch-cluster in /usr/local/lib/python3.11/dist-packages (1.6.3+pt26cpu)\n","Requirement already satisfied: pyg-lib in /usr/local/lib/python3.11/dist-packages (0.4.0+pt26cpu)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.15.3)\n","Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (2.0.2)\n","Looking in links: https://data.pyg.org/whl/torch-2.6.0+cpu.html\n","Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (2.7.0)\n","Requirement already satisfied: torch-scatter in /usr/local/lib/python3.11/dist-packages (2.1.2+pt26cpu)\n","Requirement already satisfied: torch-sparse in /usr/local/lib/python3.11/dist-packages (0.6.18+pt26cpu)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.5.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.15.3)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.4.26)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["\n","\n","# !! DUE TO THE CONFIDENTIALITY OF THE ORIGINAL DATASET, WE CANNOT DISTRIBUTE IT. !!\n","\n","# !! THIS CODE BLOCK PERFORMS 100 RANDOM SAMPLES OF THE DATASET AND SAVES THEM, !!\n","\n","# !! ALLOWING EXPERIMENTS TO BE REPRODUCED WITHOUT SHARING THE RAW DATA. !!\n","\n","\n","\n","# # sampling_pipeline.py\n","# from google.colab import drive\n","# import subprocess\n","# import os\n","# from tqdm import trange\n","\n","# # 1. Mount your Drive\n","# drive.mount('/content/drive', force_remount=True)\n","\n","# # 2. Configuration\n","# CITIES     = [\"Chicago\", \"SF\", \"NY\"]\n","# NUM_CATCH  = 100\n","# SIDE_LEN   = 3000\n","# DRIVE_DATA = \"/content/drive/MyDrive/FractalGCL/city/data\"\n","# TEMP_DATA  = \"/content/data\"\n","\n","# # 3. Run the pipeline 100 times with a progress bar\n","# for i in trange(1, 101, desc=\"Sampling runs\"):\n","#     # a) Refresh raw data\n","#     subprocess.run([\"rm\", \"-rf\", TEMP_DATA], check=True)\n","#     subprocess.run([\"cp\", \"-r\", DRIVE_DATA, TEMP_DATA], check=True)\n","\n","#     # b) Process each city\n","#     for city in CITIES:\n","#         # Generate GIS features\n","#         subprocess.run([\n","#             \"python3\", \"/content/1-gis_processing.py\",\n","#             \"--city\", city,\n","#             \"--num_catchment\", str(NUM_CATCH),\n","#             \"--side_length\",  str(SIDE_LEN)\n","#         ], check=True)\n","\n","#         # Build homogeneous PyG graph data\n","#         subprocess.run([\n","#             \"python3\", \"/content/2-generate_graph_data_homo.py\",\n","#             \"--city\", city\n","#         ], check=True)\n","\n","#         # c) Save this iteration's output\n","#         src = os.path.join(\n","#             TEMP_DATA,\n","#             f\"{city}-share_data\",\n","#             \"processed\"\n","#         )\n","#         dst = os.path.join(\n","#             DRIVE_DATA,\n","#             f\"{city}-share_data\",\n","#             f\"processed_{i}\"\n","#         )\n","#         subprocess.run([\"rm\", \"-rf\", dst], check=True)\n","#         subprocess.run([\"cp\", \"-r\", src, dst], check=True)\n","\n","# # Done: you will find directories\n","# #   drive/MyDrive/FractalGCL/city/data/Chicago-share_data/processed_1\n","# #   ...\n","# #   drive/MyDrive/FractalGCL/city/data/Chicago-share_data/processed_100\n","# # and similarly for SF and NY.\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IEX8loGyWpjh","executionInfo":{"status":"ok","timestamp":1747631358438,"user_tz":-60,"elapsed":8614476,"user":{"displayName":"Nero Li","userId":"16312290114531733443"}},"outputId":"8efc9bad-2e2b-455a-d948-e4c9a4537c0d"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["Sampling runs: 100%|██████████| 100/100 [2:23:29<00:00, 86.09s/it] \n"]}]},{"cell_type":"code","source":["\n","\n","# !! THIS FUNCTION SAMPLES DATA FOR THE FULL PIPELINE, BUT IT IS COMMENTED OUT BECAUSE THE DATA CANNOT BE FULLY OPENED. !!\n","\n","\n","\n","# %%bash\n","# set -e\n","#\n","# # List of cities you want to process\n","# CITIES=(\"Chicago\" \"SF\" \"NY\")\n","#\n","# # Sampling count and window size for each city (tweak as needed)\n","# NUM_CATCH=100\n","# SIDE_LEN=3000\n","#\n","# # Copy the original data directory to /content\n","# rm -rf /content/data\n","# cp -r /content/drive/MyDrive/FractalGCL/city/data /content/\n","#\n","# for city in \"${CITIES[@]}\"; do\n","#   echo \"▶️  Pre-processing ${city} …\"\n","#\n","#   # 1) Generate GIS features\n","#   python3 /content/1-gis_processing.py \\\n","#     --city \"$city\" \\\n","#     --num_catchment $NUM_CATCH \\\n","#     --side_length $SIDE_LEN\n","#\n","#   # 2) Build homogeneous PyG graph data\n","#   python3 /content/2-generate_graph_data_homo.py \\\n","#     --city \"$city\"\n","#\n","#   # 3) Sync back to Drive (overwrite the city’s processed directory)\n","#   rm -rf \"/content/drive/MyDrive/FractalGCL/city/data/${city}-share_data/processed\"\n","#   cp -r \"/content/data/${city}-share_data/processed\" \\\n","#         \"/content/drive/MyDrive/FractalGCL/city/data/${city}-share_data/\"\n","#\n","#   echo \"✅  ${city} pre-processing complete\"\n","# done\n","#\n","# echo \"🎉  All cities processed successfully\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jRYJVtUdanH0","executionInfo":{"status":"ok","timestamp":1747590183719,"user_tz":-60,"elapsed":48084,"user":{"displayName":"Nero Li","userId":"16312290114531733443"}},"outputId":"9435488d-e885-4e86-8d36-e3440c4ef5d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["▶️  Pre-processing Chicago …\n","Loading population data for Chicago…\n","Population data loaded. Total zones: 97\n","Loading POI data for Chicago…\n","POI data loaded. Total points: 54541\n","Loading road-network data for Chicago…\n","Road-network data loaded. Total nodes: 29117 Total edges: 76702\n","Transforming road-network coordinates to EPSG:3395…\n","Coordinate transformation complete.\n","Loading accident data for Chicago…\n","Accident data loaded. Total accidents: 4308\n","Loading demand data…\n","Demand data loaded. Shape: (97, 24, 4)\n","Generating features for 100 random locations…\n","Feature generation complete.\n","Feature data saved to data/Chicago-share_data/processed/feature_data.csv.\n","Demand features saved to data/Chicago-share_data/processed/demand_features.npy.\n","Subgraph list saved to data/Chicago-share_data/processed/sub_graph_list.pkl.\n","Feature table loaded from 'data/Chicago-share_data/processed/feature_data.csv'.\n","Sub-graph list loaded from 'data/Chicago-share_data/processed/sub_graph_list.pkl'.\n","Demand tensor loaded from 'data/Chicago-share_data/processed/demand_features.npy', shape: (100, 24, 4)\n","Detected 9 unique node types.\n","Converted 100 sub-graphs; skipped 0 empty graphs.\n","PyG Data list saved to 'data/Chicago-share_data/processed/data_list.pt'.\n","✅  Chicago pre-processing complete\n","▶️  Pre-processing SF …\n","Loading population data for SF…\n","Population data loaded. Total zones: 233\n","Loading POI data for SF…\n","POI data loaded. Total points: 29455\n","Loading road-network data for SF…\n","Road-network data loaded. Total nodes: 9927 Total edges: 27434\n","Transforming road-network coordinates to EPSG:3395…\n","Coordinate transformation complete.\n","Loading accident data for SF…\n","Accident data loaded. Total accidents: 2911\n","Loading demand data…\n","Demand data loaded. Shape: (233, 24, 4)\n","Generating features for 100 random locations…\n","Feature generation complete.\n","Feature data saved to data/SF-share_data/processed/feature_data.csv.\n","Demand features saved to data/SF-share_data/processed/demand_features.npy.\n","Subgraph list saved to data/SF-share_data/processed/sub_graph_list.pkl.\n","Feature table loaded from 'data/SF-share_data/processed/feature_data.csv'.\n","Sub-graph list loaded from 'data/SF-share_data/processed/sub_graph_list.pkl'.\n","Demand tensor loaded from 'data/SF-share_data/processed/demand_features.npy', shape: (100, 24, 4)\n","Detected 7 unique node types.\n","Converted 100 sub-graphs; skipped 0 empty graphs.\n","PyG Data list saved to 'data/SF-share_data/processed/data_list.pt'.\n","✅  SF pre-processing complete\n","▶️  Pre-processing NY …\n","Loading population data for NY…\n","Population data loaded. Total zones: 225\n","Loading POI data for NY…\n","POI data loaded. Total points: 167926\n","Loading road-network data for NY…\n","Road-network data loaded. Total nodes: 55292 Total edges: 139461\n","Transforming road-network coordinates to EPSG:3395…\n","Coordinate transformation complete.\n","Loading accident data for NY…\n","Accident data loaded. Total accidents: 9350\n","Loading demand data…\n","Demand data loaded. Shape: (225, 24, 4)\n","Generating features for 100 random locations…\n","Feature generation complete.\n","Feature data saved to data/NY-share_data/processed/feature_data.csv.\n","Demand features saved to data/NY-share_data/processed/demand_features.npy.\n","Subgraph list saved to data/NY-share_data/processed/sub_graph_list.pkl.\n","Feature table loaded from 'data/NY-share_data/processed/feature_data.csv'.\n","Sub-graph list loaded from 'data/NY-share_data/processed/sub_graph_list.pkl'.\n","Demand tensor loaded from 'data/NY-share_data/processed/demand_features.npy', shape: (100, 24, 4)\n","Detected 11 unique node types.\n","Converted 100 sub-graphs; skipped 0 empty graphs.\n","PyG Data list saved to 'data/NY-share_data/processed/data_list.pt'.\n","✅  NY pre-processing complete\n","🎉  All cities processed successfully\n"]},{"output_type":"stream","name":"stderr","text":["\rTransforming Network Coordinates:   0%|          | 0/29117 [00:00<?, ?it/s]\rTransforming Network Coordinates: 100%|██████████| 29117/29117 [00:00<00:00, 929566.75it/s]\n","\rProcessing Catchments:   0%|          | 0/100 [00:00<?, ?it/s]\rProcessing Catchments:   4%|▍         | 4/100 [00:00<00:02, 37.87it/s]\rProcessing Catchments:   8%|▊         | 8/100 [00:00<00:02, 38.68it/s]\rProcessing Catchments:  12%|█▏        | 12/100 [00:00<00:02, 35.46it/s]\rProcessing Catchments:  16%|█▌        | 16/100 [00:00<00:02, 35.45it/s]\rProcessing Catchments:  20%|██        | 20/100 [00:00<00:02, 36.69it/s]\rProcessing Catchments:  24%|██▍       | 24/100 [00:00<00:02, 36.86it/s]\rProcessing Catchments:  28%|██▊       | 28/100 [00:00<00:01, 37.46it/s]\rProcessing Catchments:  32%|███▏      | 32/100 [00:00<00:01, 37.60it/s]\rProcessing Catchments:  36%|███▌      | 36/100 [00:00<00:01, 37.04it/s]\rProcessing Catchments:  40%|████      | 40/100 [00:01<00:01, 37.06it/s]\rProcessing Catchments:  44%|████▍     | 44/100 [00:01<00:01, 37.81it/s]\rProcessing Catchments:  48%|████▊     | 48/100 [00:01<00:01, 37.75it/s]\rProcessing Catchments:  52%|█████▏    | 52/100 [00:01<00:01, 37.85it/s]\rProcessing Catchments:  56%|█████▌    | 56/100 [00:01<00:01, 37.57it/s]\rProcessing Catchments:  60%|██████    | 60/100 [00:01<00:01, 37.21it/s]\rProcessing Catchments:  64%|██████▍   | 64/100 [00:01<00:00, 37.00it/s]\rProcessing Catchments:  69%|██████▉   | 69/100 [00:01<00:00, 37.84it/s]\rProcessing Catchments:  73%|███████▎  | 73/100 [00:02<00:01, 22.98it/s]\rProcessing Catchments:  77%|███████▋  | 77/100 [00:02<00:00, 26.16it/s]\rProcessing Catchments:  81%|████████  | 81/100 [00:02<00:00, 28.04it/s]\rProcessing Catchments:  85%|████████▌ | 85/100 [00:02<00:00, 30.02it/s]\rProcessing Catchments:  89%|████████▉ | 89/100 [00:02<00:00, 32.31it/s]\rProcessing Catchments:  94%|█████████▍| 94/100 [00:02<00:00, 34.87it/s]\rProcessing Catchments:  98%|█████████▊| 98/100 [00:02<00:00, 35.52it/s]\rProcessing Catchments: 100%|██████████| 100/100 [00:02<00:00, 34.37it/s]\n","\rConverting to PyG Data:   0%|          | 0/100 [00:00<?, ?it/s]\rConverting to PyG Data:  12%|█▏        | 12/100 [00:00<00:00, 108.28it/s]\rConverting to PyG Data:  24%|██▍       | 24/100 [00:00<00:00, 108.63it/s]\rConverting to PyG Data:  35%|███▌      | 35/100 [00:00<00:00, 101.92it/s]\rConverting to PyG Data:  47%|████▋     | 47/100 [00:00<00:00, 106.55it/s]\rConverting to PyG Data:  58%|█████▊    | 58/100 [00:00<00:00, 107.40it/s]\rConverting to PyG Data:  70%|███████   | 70/100 [00:00<00:00, 109.36it/s]\rConverting to PyG Data:  82%|████████▏ | 82/100 [00:00<00:00, 110.82it/s]\rConverting to PyG Data:  96%|█████████▌| 96/100 [00:00<00:00, 118.90it/s]\rConverting to PyG Data: 100%|██████████| 100/100 [00:00<00:00, 110.61it/s]\n","\rTransforming Network Coordinates:   0%|          | 0/9927 [00:00<?, ?it/s]\rTransforming Network Coordinates: 100%|██████████| 9927/9927 [00:00<00:00, 897713.63it/s]\n","\rProcessing Catchments:   0%|          | 0/100 [00:00<?, ?it/s]\rProcessing Catchments:   4%|▍         | 4/100 [00:00<00:02, 36.53it/s]\rProcessing Catchments:   8%|▊         | 8/100 [00:00<00:02, 37.86it/s]\rProcessing Catchments:  12%|█▏        | 12/100 [00:00<00:02, 38.48it/s]\rProcessing Catchments:  16%|█▌        | 16/100 [00:00<00:02, 36.90it/s]\rProcessing Catchments:  21%|██        | 21/100 [00:00<00:02, 37.33it/s]\rProcessing Catchments:  25%|██▌       | 25/100 [00:00<00:02, 28.59it/s]\rProcessing Catchments:  29%|██▉       | 29/100 [00:00<00:02, 31.03it/s]\rProcessing Catchments:  33%|███▎      | 33/100 [00:00<00:02, 32.49it/s]\rProcessing Catchments:  38%|███▊      | 38/100 [00:01<00:01, 34.84it/s]\rProcessing Catchments:  43%|████▎     | 43/100 [00:01<00:01, 37.12it/s]\rProcessing Catchments:  47%|████▋     | 47/100 [00:01<00:01, 36.33it/s]\rProcessing Catchments:  51%|█████     | 51/100 [00:01<00:01, 35.47it/s]\rProcessing Catchments:  55%|█████▌    | 55/100 [00:01<00:01, 25.08it/s]\rProcessing Catchments:  59%|█████▉    | 59/100 [00:01<00:01, 27.94it/s]\rProcessing Catchments:  63%|██████▎   | 63/100 [00:01<00:01, 29.85it/s]\rProcessing Catchments:  67%|██████▋   | 67/100 [00:02<00:01, 32.19it/s]\rProcessing Catchments:  71%|███████   | 71/100 [00:02<00:00, 33.99it/s]\rProcessing Catchments:  75%|███████▌  | 75/100 [00:02<00:00, 35.32it/s]\rProcessing Catchments:  79%|███████▉  | 79/100 [00:02<00:00, 35.93it/s]\rProcessing Catchments:  83%|████████▎ | 83/100 [00:02<00:00, 35.38it/s]\rProcessing Catchments:  87%|████████▋ | 87/100 [00:02<00:00, 35.89it/s]\rProcessing Catchments:  91%|█████████ | 91/100 [00:02<00:00, 25.57it/s]\rProcessing Catchments:  95%|█████████▌| 95/100 [00:02<00:00, 28.01it/s]\rProcessing Catchments:  99%|█████████▉| 99/100 [00:03<00:00, 30.71it/s]\rProcessing Catchments: 100%|██████████| 100/100 [00:03<00:00, 32.38it/s]\n","\rConverting to PyG Data:   0%|          | 0/100 [00:00<?, ?it/s]\rConverting to PyG Data:   6%|▌         | 6/100 [00:00<00:01, 50.70it/s]\rConverting to PyG Data:  12%|█▏        | 12/100 [00:00<00:01, 51.97it/s]\rConverting to PyG Data:  18%|█▊        | 18/100 [00:00<00:01, 48.81it/s]\rConverting to PyG Data:  24%|██▍       | 24/100 [00:00<00:01, 49.21it/s]\rConverting to PyG Data:  30%|███       | 30/100 [00:00<00:01, 51.00it/s]\rConverting to PyG Data:  36%|███▌      | 36/100 [00:00<00:01, 49.71it/s]\rConverting to PyG Data:  44%|████▍     | 44/100 [00:00<00:01, 55.07it/s]\rConverting to PyG Data:  50%|█████     | 50/100 [00:01<00:01, 29.64it/s]\rConverting to PyG Data:  56%|█████▌    | 56/100 [00:01<00:01, 34.65it/s]\rConverting to PyG Data:  62%|██████▏   | 62/100 [00:01<00:00, 38.11it/s]\rConverting to PyG Data:  68%|██████▊   | 68/100 [00:01<00:00, 41.92it/s]\rConverting to PyG Data:  75%|███████▌  | 75/100 [00:01<00:00, 47.46it/s]\rConverting to PyG Data:  81%|████████  | 81/100 [00:01<00:00, 49.98it/s]\rConverting to PyG Data:  87%|████████▋ | 87/100 [00:01<00:00, 50.09it/s]\rConverting to PyG Data:  93%|█████████▎| 93/100 [00:02<00:00, 50.36it/s]\rConverting to PyG Data: 100%|██████████| 100/100 [00:02<00:00, 53.97it/s]\rConverting to PyG Data: 100%|██████████| 100/100 [00:02<00:00, 46.28it/s]\n","\rTransforming Network Coordinates:   0%|          | 0/55292 [00:00<?, ?it/s]\rTransforming Network Coordinates: 100%|██████████| 55292/55292 [00:00<00:00, 929706.06it/s]\n","\rProcessing Catchments:   0%|          | 0/100 [00:00<?, ?it/s]\rProcessing Catchments:   2%|▏         | 2/100 [00:00<00:05, 18.37it/s]\rProcessing Catchments:   4%|▍         | 4/100 [00:00<00:05, 18.63it/s]\rProcessing Catchments:   7%|▋         | 7/100 [00:00<00:04, 18.99it/s]\rProcessing Catchments:   9%|▉         | 9/100 [00:00<00:04, 18.59it/s]\rProcessing Catchments:  11%|█         | 11/100 [00:00<00:04, 18.84it/s]\rProcessing Catchments:  13%|█▎        | 13/100 [00:00<00:04, 18.51it/s]\rProcessing Catchments:  15%|█▌        | 15/100 [00:00<00:04, 18.51it/s]\rProcessing Catchments:  17%|█▋        | 17/100 [00:00<00:04, 18.38it/s]\rProcessing Catchments:  19%|█▉        | 19/100 [00:01<00:04, 18.25it/s]\rProcessing Catchments:  22%|██▏       | 22/100 [00:01<00:04, 19.04it/s]\rProcessing Catchments:  24%|██▍       | 24/100 [00:01<00:04, 18.97it/s]\rProcessing Catchments:  26%|██▌       | 26/100 [00:01<00:03, 19.00it/s]\rProcessing Catchments:  28%|██▊       | 28/100 [00:01<00:03, 19.27it/s]\rProcessing Catchments:  30%|███       | 30/100 [00:01<00:03, 19.34it/s]\rProcessing Catchments:  32%|███▏      | 32/100 [00:01<00:03, 19.11it/s]\rProcessing Catchments:  34%|███▍      | 34/100 [00:02<00:07,  9.36it/s]\rProcessing Catchments:  36%|███▌      | 36/100 [00:02<00:05, 11.07it/s]\rProcessing Catchments:  39%|███▉      | 39/100 [00:02<00:04, 13.59it/s]\rProcessing Catchments:  41%|████      | 41/100 [00:02<00:04, 14.71it/s]\rProcessing Catchments:  44%|████▍     | 44/100 [00:02<00:03, 16.27it/s]\rProcessing Catchments:  46%|████▌     | 46/100 [00:02<00:03, 16.91it/s]\rProcessing Catchments:  48%|████▊     | 48/100 [00:02<00:03, 17.00it/s]\rProcessing Catchments:  50%|█████     | 50/100 [00:02<00:02, 17.68it/s]\rProcessing Catchments:  52%|█████▏    | 52/100 [00:03<00:02, 17.98it/s]\rProcessing Catchments:  54%|█████▍    | 54/100 [00:03<00:02, 17.97it/s]\rProcessing Catchments:  56%|█████▌    | 56/100 [00:03<00:02, 18.06it/s]\rProcessing Catchments:  58%|█████▊    | 58/100 [00:03<00:02, 18.17it/s]\rProcessing Catchments:  60%|██████    | 60/100 [00:03<00:02, 18.35it/s]\rProcessing Catchments:  62%|██████▏   | 62/100 [00:03<00:02, 18.16it/s]\rProcessing Catchments:  64%|██████▍   | 64/100 [00:03<00:01, 18.19it/s]\rProcessing Catchments:  66%|██████▌   | 66/100 [00:03<00:01, 18.23it/s]\rProcessing Catchments:  68%|██████▊   | 68/100 [00:03<00:01, 18.28it/s]\rProcessing Catchments:  70%|███████   | 70/100 [00:04<00:01, 18.16it/s]\rProcessing Catchments:  72%|███████▏  | 72/100 [00:04<00:01, 18.36it/s]\rProcessing Catchments:  74%|███████▍  | 74/100 [00:04<00:01, 18.04it/s]\rProcessing Catchments:  76%|███████▌  | 76/100 [00:04<00:01, 18.31it/s]\rProcessing Catchments:  78%|███████▊  | 78/100 [00:04<00:01, 18.54it/s]\rProcessing Catchments:  80%|████████  | 80/100 [00:04<00:01, 18.15it/s]\rProcessing Catchments:  82%|████████▏ | 82/100 [00:04<00:00, 18.41it/s]\rProcessing Catchments:  84%|████████▍ | 84/100 [00:04<00:00, 18.75it/s]\rProcessing Catchments:  87%|████████▋ | 87/100 [00:04<00:00, 19.19it/s]\rProcessing Catchments:  89%|████████▉ | 89/100 [00:05<00:00, 19.37it/s]\rProcessing Catchments:  91%|█████████ | 91/100 [00:05<00:00, 19.42it/s]\rProcessing Catchments:  93%|█████████▎| 93/100 [00:05<00:00, 19.32it/s]\rProcessing Catchments:  95%|█████████▌| 95/100 [00:05<00:00, 18.86it/s]\rProcessing Catchments:  97%|█████████▋| 97/100 [00:05<00:00, 18.96it/s]\rProcessing Catchments:  99%|█████████▉| 99/100 [00:05<00:00, 18.89it/s]\rProcessing Catchments: 100%|██████████| 100/100 [00:05<00:00, 17.60it/s]\n","\rConverting to PyG Data:   0%|          | 0/100 [00:00<?, ?it/s]\rConverting to PyG Data:   8%|▊         | 8/100 [00:00<00:01, 77.98it/s]\rConverting to PyG Data:  16%|█▌        | 16/100 [00:00<00:01, 70.81it/s]\rConverting to PyG Data:  24%|██▍       | 24/100 [00:00<00:01, 68.13it/s]\rConverting to PyG Data:  31%|███       | 31/100 [00:00<00:01, 68.67it/s]\rConverting to PyG Data:  40%|████      | 40/100 [00:00<00:00, 73.49it/s]\rConverting to PyG Data:  48%|████▊     | 48/100 [00:00<00:00, 71.46it/s]\rConverting to PyG Data:  56%|█████▌    | 56/100 [00:00<00:00, 72.28it/s]\rConverting to PyG Data:  64%|██████▍   | 64/100 [00:00<00:00, 68.75it/s]\rConverting to PyG Data:  72%|███████▏  | 72/100 [00:01<00:00, 71.74it/s]\rConverting to PyG Data:  80%|████████  | 80/100 [00:01<00:00, 72.73it/s]\rConverting to PyG Data:  89%|████████▉ | 89/100 [00:01<00:00, 77.61it/s]\rConverting to PyG Data:  97%|█████████▋| 97/100 [00:01<00:00, 75.77it/s]\rConverting to PyG Data: 100%|██████████| 100/100 [00:01<00:00, 72.43it/s]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"5ePNfEB6UKYc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# —— Block: Train five baseline encoders and keep them in memory ——\n","\n","import torch\n","import torch.nn.functional as F\n","from torch_geometric.nn import SAGEConv, global_mean_pool\n","from torch_geometric.data import Data\n","from torch_geometric.loader import DataLoader\n","from torch_geometric.utils import dropout_edge, subgraph\n","import numpy as np\n","from sklearn.svm import SVC\n","from sklearn.model_selection import cross_val_score\n","from gis_utils import get_file_paths\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# ─── Generic Encoder ───────────────────────────────────────────────────────────\n","class Encoder(torch.nn.Module):\n","    def __init__(self, in_dim, hidden, embed_dim):\n","        super().__init__()\n","        self.conv1 = SAGEConv(in_dim, hidden)\n","        self.conv2 = SAGEConv(hidden, hidden)\n","        self.proj  = torch.nn.Linear(hidden, embed_dim)\n","    def forward(self, x, ei, batch=None):\n","        x = F.relu(self.conv1(x, ei))\n","        x = F.relu(self.conv2(x, ei))\n","        x = self.proj(x)\n","        # Fix potential (embed_dim, N) output\n","        if x.dim() == 2 and x.size(0) == self.proj.out_features and x.size(1) != self.proj.out_features:\n","            x = x.t()\n","        return x\n","\n","# ─── DGI ───────────────────────────────────────────────────────────────────────\n","def train_dgi(data_list, in_dim, hidden, embed_dim,\n","              lr, epochs, batch_size):\n","    enc = Encoder(in_dim, hidden, embed_dim).to(device)\n","    opt = torch.optim.Adam(enc.parameters(), lr=lr)\n","    loader = DataLoader(data_list, batch_size=batch_size, shuffle=True)\n","    for ep in range(1, epochs + 1):\n","        total = 0\n","        for batch in loader:\n","            batch = batch.to(device)\n","            z_pos = enc(batch.x, batch.edge_index, batch.batch)\n","            perm  = torch.randperm(batch.x.size(0), device=device)\n","            z_neg = enc(batch.x[perm], batch.edge_index, batch.batch)\n","            s      = torch.sigmoid(global_mean_pool(z_pos, batch.batch))\n","            s_node = s[batch.batch]\n","            pos = (z_pos * s_node).sum(dim=1)\n","            neg = (z_neg * s_node).sum(dim=1)\n","            logits = torch.stack([pos, neg], dim=1)\n","            labels = torch.zeros(batch.x.size(0), device=device, dtype=torch.long)\n","            loss   = F.cross_entropy(logits, labels)\n","            opt.zero_grad(); loss.backward(); opt.step()\n","            total += loss.item()\n","        print(f\"[DGI] {ep}/{epochs} — Loss: {total/len(loader):.4f}\")\n","    return enc\n","\n","# ─── InfoGraph ────────────────────────────────────────────────────────────────\n","def train_infograph(data_list, in_dim, hidden, embed_dim,\n","                    lr, epochs, batch_size, temp):\n","    enc = Encoder(in_dim, hidden, embed_dim).to(device)\n","    summary_net = torch.nn.Linear(embed_dim, embed_dim).to(device)\n","    opt = torch.optim.Adam(list(enc.parameters()) + list(summary_net.parameters()), lr=lr)\n","    loader = DataLoader(data_list, batch_size=batch_size, shuffle=True)\n","    for ep in range(1, epochs + 1):\n","        total = 0\n","        for batch in loader:\n","            batch = batch.to(device)\n","            h = enc(batch.x, batch.edge_index, batch.batch)      # (N, E)\n","            g = global_mean_pool(h, batch.batch)                 # (B, E)\n","            s = summary_net(g)                                   # (B, E)\n","            logits = (h @ s.t()) / temp                          # (N, B)\n","            labels = batch.batch                                 # node → graph idx\n","            loss = F.cross_entropy(logits, labels)\n","            opt.zero_grad(); loss.backward(); opt.step()\n","            total += loss.item()\n","        print(f\"[InfoGraph] {ep}/{epochs} — Loss: {total/len(loader):.4f}\")\n","    return enc\n","\n","# ─── GCL (hand-written) ────────────────────────────────────────────────────────\n","def train_gcl_manual(data_list, in_dim, hidden, embed_dim,\n","                     lr, epochs, batch_size,\n","                     drop_prob, subgraph_ratio, temp):\n","    enc = Encoder(in_dim, hidden, embed_dim).to(device)\n","    opt = torch.optim.Adam(enc.parameters(), lr=lr)\n","    loader = DataLoader(data_list, batch_size=batch_size, shuffle=True)\n","\n","    def nt_xent(z1, z2):\n","        z1, z2 = F.normalize(z1, dim=1), F.normalize(z2, dim=1)\n","        logits = torch.mm(z1, z2.t()) / temp\n","        labels = torch.arange(z1.size(0), device=device)\n","        return F.cross_entropy(logits, labels)\n","\n","    for ep in range(1, epochs + 1):\n","        total = 0\n","        for batch in loader:\n","            batch = batch.to(device)\n","\n","            # Augmentation 1: edge dropout\n","            ei1, _ = dropout_edge(batch.edge_index, p=drop_prob)\n","            b1 = Data(x=batch.x, edge_index=ei1, batch=batch.batch).to(device)\n","\n","            # Augmentation 2: node-induced subgraph\n","            N = batch.x.size(0)\n","            k = max(2, int(N * subgraph_ratio))\n","            idx = torch.randperm(N, device=device)[:k].tolist()          # to list\n","            ei2, _ = subgraph(idx,\n","                              batch.edge_index,\n","                              relabel_nodes=True,\n","                              num_nodes=N)                                # specify num_nodes\n","            b2 = Data(x=batch.x[idx], edge_index=ei2, batch=batch.batch[idx]).to(device)\n","\n","            # Contrastive loss\n","            g1 = global_mean_pool(enc(b1.x, b1.edge_index, b1.batch), b1.batch)\n","            g2 = global_mean_pool(enc(b2.x, b2.edge_index, b2.batch), b2.batch)\n","            loss = nt_xent(g1, g2)\n","\n","            opt.zero_grad()\n","            loss.backward()\n","            opt.step()\n","\n","            total += loss.item()\n","\n","        print(f\"[GCL] {ep}/{epochs} — Loss: {total/len(loader):.4f}\")\n","\n","    return enc\n","\n","# ─── JOAO ──────────────────────────────────────────────────────────────────────\n","def train_joao(data_list, in_dim, hidden, embed_dim,\n","               lr, epochs, batch_size):\n","    # Two augmentations: drop-edge & attribute mask\n","    aug_fns = [\n","        lambda d: Data(x=d.x,\n","                       edge_index=dropout_edge(d.edge_index, p=0.2)[0],\n","                       batch=d.batch),\n","        lambda d: Data(x=d.x.masked_fill(torch.rand_like(d.x) < 0.2, 0),\n","                       edge_index=d.edge_index,\n","                       batch=d.batch)\n","    ]\n","    alpha = torch.nn.Parameter(torch.zeros(len(aug_fns), device=device))\n","    enc   = Encoder(in_dim, hidden, embed_dim).to(device)\n","    opt   = torch.optim.Adam(list(enc.parameters()) + [alpha], lr=lr)\n","    loader = DataLoader(data_list, batch_size=batch_size, shuffle=True)\n","\n","    for ep in range(1, epochs + 1):\n","        total = 0\n","        for batch in loader:\n","            batch = batch.to(device)\n","            weights = torch.softmax(alpha, dim=0)\n","            loss_sum = 0\n","            for w, aug in zip(weights, aug_fns):\n","                b1 = aug(batch).to(device)\n","                b2 = aug(batch).to(device)\n","                g1 = global_mean_pool(enc(b1.x, b1.edge_index, b1.batch), b1.batch)\n","                g2 = global_mean_pool(enc(b2.x, b2.edge_index, b2.batch), b2.batch)\n","                logits = (F.normalize(g1, 1) @ F.normalize(g2, 1).t()) / 0.5\n","                labels = torch.arange(g1.size(0), device=device)\n","                loss = F.cross_entropy(logits, labels)\n","                loss_sum = loss_sum + w * loss\n","            opt.zero_grad(); loss_sum.backward(); opt.step()\n","            total += loss_sum.item()\n","        print(f\"[JOAO] {ep}/{epochs} — Loss: {total/len(loader):.4f}\")\n","    return enc\n","\n","# ─── SimGRACE ─────────────────────────────────────────────────────────────────\n","def train_simgrace(data_list, in_dim, hidden, embed_dim,\n","                   lr=1e-3, epochs=20, batch_size=32,\n","                   subgraph_ratio=0.8, mask_prob=0.2, temp=0.5):\n","    \"\"\"\n","    SimGRACE: subgraph + mask augmentations with explicit num_nodes.\n","    \"\"\"\n","    def subview(data):\n","        # For a Batch object, num_nodes is the total node count\n","        N = data.num_nodes if hasattr(data, 'num_nodes') else data.x.size(0)\n","        k = max(2, int(N * subgraph_ratio))\n","        idx = torch.randperm(N, device=data.x.device)[:k].tolist()\n","        ei, _ = subgraph(idx, data.edge_index,\n","                         relabel_nodes=True,\n","                         num_nodes=N)\n","        x_new   = data.x[idx]\n","        batch_n = data.batch[idx]\n","        return Data(x=x_new, edge_index=ei, batch=batch_n)\n","\n","    def maskview(data):\n","        N = data.x.size(0)\n","        mask = torch.rand(N, device=data.x.device) < mask_prob\n","        x_new = data.x.clone()\n","        x_new[mask] = 0\n","        return Data(x=x_new, edge_index=data.edge_index, batch=data.batch)\n","\n","    enc = Encoder(in_dim, hidden, embed_dim).to(device)\n","    opt = torch.optim.Adam(enc.parameters(), lr=lr)\n","    loader = DataLoader(data_list, batch_size=batch_size, shuffle=True)\n","\n","    def nt_xent(z1, z2):\n","        z1, z2 = F.normalize(z1, dim=1), F.normalize(z2, dim=1)\n","        logits = torch.mm(z1, z2.t()) / temp\n","        labels = torch.arange(z1.size(0), device=device)\n","        return F.cross_entropy(logits, labels)\n","\n","    for ep in range(1, epochs + 1):\n","        total = 0.0\n","        for batch in loader:\n","            batch = batch.to(device)\n","            b1 = subview(batch).to(device)\n","            b2 = maskview(batch).to(device)\n","            g1 = global_mean_pool(enc(b1.x, b1.edge_index, b1.batch), b1.batch)\n","            g2 = global_mean_pool(enc(b2.x, b2.edge_index, b2.batch), b2.batch)\n","            loss = nt_xent(g1, g2)\n","            opt.zero_grad(); loss.backward(); opt.step()\n","            total += loss.item()\n","        print(f\"[SimGRACE] {ep}/{epochs} — Loss: {total/len(loader):.4f}\")\n","    return enc\n","\n","# ─── SVM evaluation ───────────────────────────────────────────────────────────\n","def extract_embeddings(enc, data_list):\n","    enc.eval()\n","    embs = []\n","    for d in data_list:\n","        d = d.to(device)\n","        h = enc(d.x, d.edge_index, d.batch)\n","        g = global_mean_pool(h, d.batch)\n","        embs.append(g.detach().cpu().numpy())\n","    return np.vstack(embs)\n","\n","from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n","from sklearn.svm import SVC\n","import numpy as np\n","\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n","import numpy as np\n","\n","def evaluate_repeated_cv_fast(X, y,\n","                              n_splits=10,\n","                              n_repeats=1000,\n","                              random_state=42,\n","                              classifier=None):\n","    \"\"\"\n","    Repeated Stratified K-Fold, performing n_repeats × n_splits evaluations,\n","    and using a faster linear classifier (SGDClassifier by default) to speed up training.\n","    Returns (mean_accuracy, std_accuracy) rounded to 4 decimal places.\n","    \"\"\"\n","    # Replace RBF-SVC with a linear SVM (SGDClassifier with loss='hinge') to speed up training\n","    if classifier is None:\n","        classifier = SGDClassifier(loss='hinge', max_iter=1000, tol=1e-3, random_state=random_state)\n","\n","    rkf = RepeatedStratifiedKFold(\n","        n_splits=n_splits,\n","        n_repeats=n_repeats,\n","        random_state=random_state\n","    )\n","    # Run in parallel\n","    scores = cross_val_score(\n","        classifier, X, y,\n","        cv=rkf,\n","        scoring='accuracy',\n","        n_jobs=-1\n","    )\n","\n","    mean = float(np.mean(scores))\n","    std  = float(np.std(scores))\n","    return round(mean, 4), round(std, 4)\n","\n","# —— Example usage ——\n","# mean, std = evaluate_repeated_cv_fast(X_dgi, y, n_splits=10, n_repeats=5)\n","# print(f\"SVM 5×10-fold acc: {mean:.4f} ± {std:.4f}\")\n"],"metadata":{"id":"W82jq8ZB0NEN","executionInfo":{"status":"ok","timestamp":1747655616566,"user_tz":-60,"elapsed":3692,"user":{"displayName":"Nero Li","userId":"16312290114531733443"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","import networkx as nx\n","import numpy as np\n","\n","from torch_geometric.data import Data, Batch\n","from torch_geometric.loader import DataLoader\n","from torch_geometric.nn import GraphSAGE, global_mean_pool\n","from torch_geometric.utils import to_networkx, subgraph, dropout_edge\n","\n","from sklearn.linear_model import LinearRegression\n","\n","\n","def build_sage(in_dim, hidden_channels=64, num_layers=2, embed_dim=128):\n","    \"\"\"Build a GraphSAGE encoder.\"\"\"\n","    return GraphSAGE(\n","        in_channels=in_dim,\n","        hidden_channels=hidden_channels,\n","        num_layers=num_layers,\n","        out_channels=embed_dim\n","    )\n","\n","\n","def compute_box_dim(G):\n","    \"\"\"Compute the box dimension of a NetworkX graph.\"\"\"\n","    if nx.is_directed(G):\n","        G = G.to_undirected()\n","    if not nx.is_connected(G):\n","        G = G.subgraph(max(nx.connected_components(G), key=len)).copy()\n","    try:\n","        D = nx.diameter(G)\n","    except Exception:\n","        return 0.0, 0.0\n","\n","    max_l, ls, Ns = max(1, D // 2), [], []\n","    for l in range(1, max_l + 1):\n","        r, unc, cnt = l // 2, set(G.nodes()), 0\n","        if l % 2 == 0:                        # single-center covering\n","            while unc:\n","                best = max((set(nx.single_source_shortest_path_length(G, u, cutoff=r)) & unc)\n","                           for u in unc)\n","                unc -= best\n","                cnt += 1\n","        else:                                 # try dual-center covering\n","            while unc:\n","                ubest = set()\n","                for u in unc:\n","                    for v in G.neighbors(u):\n","                        uni = ((set(nx.single_source_shortest_path_length(G, u, cutoff=r)) |\n","                                set(nx.single_source_shortest_path_length(G, v, cutoff=r)))\n","                               & unc)\n","                        if len(uni) > len(ubest):\n","                            ubest = uni\n","                if ubest:\n","                    unc -= ubest\n","                else:                         # fall back to single center\n","                    best = max((set(nx.single_source_shortest_path_length(G, u, cutoff=r)) & unc)\n","                               for u in unc)\n","                    unc -= best\n","                cnt += 1\n","        ls.append(l)\n","        Ns.append(cnt)\n","\n","    if len(ls) < 2:\n","        return 0.0, 0.0\n","\n","    log_l = np.log(np.array(ls)).reshape(-1, 1)\n","    log_N = np.log(np.array(Ns))\n","    reg = LinearRegression().fit(log_l, log_N)\n","    return reg.score(log_l, log_N), -reg.coef_[0]\n","\n","\n","def renormalise(data, r=1):\n","    \"\"\"Three-Step Random-Centre Renormalisation augmentation.\"\"\"\n","    G = to_networkx(data, to_undirected=True)\n","    if not nx.is_connected(G):\n","        G = G.subgraph(max(nx.connected_components(G), key=len)).copy()\n","\n","    nodes, supers = set(G.nodes()), []\n","    while nodes:\n","        u = nodes.pop()\n","        reach = set(nx.single_source_shortest_path_length(G, u, cutoff=r).keys())\n","        U = {u} | (reach & nodes)\n","        supers.append(U)\n","        nodes -= U\n","\n","    assign = {v: i for i, U in enumerate(supers) for v in U}\n","    edges = {\n","        (min(assign[u], assign[v]), max(assign[u], assign[v]))\n","        for u, v in G.edges() if assign[u] != assign[v]\n","    }\n","    feats = [\n","        data.x[torch.tensor(list(U), dtype=torch.long)].mean(dim=0)\n","        for U in supers\n","    ]\n","    x_new = torch.stack(feats, dim=0)\n","    ei = (torch.tensor(list(edges), dtype=torch.long).t().contiguous()\n","          if edges else torch.empty((2, 0), dtype=torch.long))\n","    return Data(x=x_new, edge_index=ei)\n","\n","\n","def augment_drop(data, p=0.2):\n","    \"\"\"Node-drop augmentation with fallback when everything is dropped.\"\"\"\n","    Nn = data.x.size(0)\n","    mask = torch.rand(Nn, device=data.x.device) > p\n","    idx = mask.nonzero(as_tuple=False).view(-1)\n","    if idx.numel() == 0:  # if all nodes were dropped, randomly keep one\n","        idx = torch.tensor([torch.randint(Nn, (1,), device=data.x.device)],\n","                           dtype=torch.long)\n","    ei, _ = subgraph(idx, data.edge_index, relabel_nodes=True, num_nodes=Nn)\n","    return Data(x=data.x[idx], edge_index=ei)\n","\n","\n","def extract_embeddings(enc, data_list):\n","    \"\"\"Extract graph-level embeddings for a list of PyG Data objects.\"\"\"\n","    enc.eval()\n","    out = []\n","    for d in data_list:\n","        batch = torch.zeros(d.x.size(0), dtype=torch.long, device=d.x.device)\n","        h = enc(d.x, d.edge_index, batch)\n","        g = global_mean_pool(h, batch)\n","        out.append(g.detach().cpu().numpy())\n","    return np.vstack(out)\n","\n","\n","def train_fractal(data_list, in_dim, diameters, dims,\n","                  hidden, layers, embed_dim,\n","                  alpha=1.0, renorm_r=1,\n","                  lr=1e-3, epochs=20, batch_size=16, drop_prob=0.2):\n","    \"\"\"Train a FractalGCL encoder and return the trained model.\"\"\"\n","    enc = build_sage(in_dim, hidden, layers, embed_dim)\n","    opt = torch.optim.Adam(enc.parameters(), lr=lr)\n","\n","    def tau2(D):\n","        \"\"\"Variance schedule used in the Gn perturbation.\"\"\"\n","        Dm = max(D, 2)\n","        return 6.0 / (Dm * (np.log(Dm) ** 2 + 1e-12))\n","\n","    enc.train()\n","    for ep in range(1, epochs + 1):\n","        perm = torch.randperm(len(data_list)).tolist()\n","        total = 0.0\n","        for i in range(0, len(data_list), batch_size):\n","            ids = perm[i:i + batch_size]\n","\n","            # Two complementary views\n","            B1 = [renormalise(data_list[j], renorm_r) for j in ids]\n","            B2 = [augment_drop(data_list[j], drop_prob) for j in ids]\n","            b1 = Batch.from_data_list(B1)\n","            b2 = Batch.from_data_list(B2)\n","\n","            h1 = enc(b1.x, b1.edge_index, b1.batch)\n","            h2 = enc(b2.x, b2.edge_index, b2.batch)\n","            z1 = global_mean_pool(h1, b1.batch)\n","            z2 = global_mean_pool(h2, b2.batch)\n","\n","            # Contrastive similarity matrix\n","            S = F.cosine_similarity(z1.unsqueeze(1), z2.unsqueeze(0), dim=-1) / 0.5  # (B, B)\n","\n","            B = S.size(0)\n","            # Dynamically construct Gn\n","            Gn = torch.zeros((B, B), device=S.device)\n","            for m in range(B):\n","                for n in range(B):\n","                    if m == n:\n","                        Gn[m, n] = torch.randn(1, device=S.device) * np.sqrt(tau2(diameters[ids[m]]))\n","                    else:\n","                        mu  = abs(dims[ids[m]] - dims[ids[n]])\n","                        var = tau2(diameters[ids[m]]) + tau2(diameters[ids[n]])\n","                        Gn[m, n] = mu + torch.randn(1, device=S.device) * np.sqrt(var)\n","\n","            S2 = S + alpha * Gn\n","            E  = torch.exp(S2)\n","            loss = (-torch.log(E.diag() / E.sum(dim=1))).mean()\n","\n","            opt.zero_grad()\n","            loss.backward()\n","            opt.step()\n","\n","            total += loss.item()\n","\n","        n_batches = (len(data_list) - 1) // batch_size + 1\n","        print(f\"[Fractal] Epoch {ep}/{epochs}  Loss = {total / n_batches:.4f}\")\n","\n","    return enc\n"],"metadata":{"id":"wKZRpk0FCQI2","executionInfo":{"status":"ok","timestamp":1747655618700,"user_tz":-60,"elapsed":145,"user":{"displayName":"Nero Li","userId":"16312290114531733443"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["from gis_utils import get_file_paths\n","import torch\n","import random\n","import os\n","\n","cities = [\"Chicago\", \"SF\", \"NY\"]\n","baseline_encoders = {}\n","\n","# for city in cities:\n","#     print(f\"\\n===== Training baselines for {city} =====\")\n","#     paths     = get_file_paths(city)\n","#     data_list = torch.load(f\"{paths['save_path']}/data_list.pt\", weights_only=False)\n","#     in_dim    = data_list[0].x.size(1)\n","#     print(f\"  • {len(data_list)} graphs, feature-dim = {in_dim}\")\n","\n","\n","for city in cities:\n","    # Randomly select a sample ID between 1 and 100\n","    sample_id = random.randint(1, 100)\n","    print(f\"\\n===== Training baselines for {city} (using sample {sample_id}) =====\")\n","\n","    # Construct the full sample directory path on Drive\n","    sample_dir = f\"/content/drive/MyDrive/FractalGCL/city/data/{city}-share_data/processed_{sample_id}\"\n","    file_path  = f\"{sample_dir}/data_list.pt\"\n","    print(\"  Loading from\", file_path)\n","\n","    # Load the sampled data list\n","    data_list = torch.load(file_path, weights_only=False)\n","    in_dim    = data_list[0].x.size(1)\n","    print(f\"  • {len(data_list)} graphs, feature-dim = {in_dim}\")\n","\n","\n","\n","    # Train each method\n","    print(\"  ⏳ DGI…\", end=\" \")\n","    dgi_enc = train_dgi(      data_list, in_dim, 64, 128, 1e-3, 20, 32)\n","    print(\"done\")\n","\n","    print(\"  ⏳ InfoGraph…\", end=\" \")\n","    infograph_enc = train_infograph(\n","        data_list, in_dim, 64, 128, 1e-3, 20, 32, 0.5\n","    )\n","    print(\"done\")\n","\n","    print(\"  ⏳ GCL…\", end=\" \")\n","    gcl_enc = train_gcl_manual(\n","        data_list, in_dim, 64, 128, 1e-3, 20, 32, 0.2, 0.8, 0.5\n","    )\n","    print(\"done\")\n","\n","    print(\"  ⏳ JOAO…\", end=\" \")\n","    joao_enc = train_joao(\n","        data_list, in_dim, 64, 128, 1e-3, 20, 32\n","    )\n","    print(\"done\")\n","\n","    print(\"  ⏳ SimGRACE…\", end=\" \")\n","    simgrace_enc = train_simgrace(\n","        data_list, in_dim, 64, 128, 1e-3, 20, 32, 0.8, 0.2, 0.5\n","    )\n","    print(\"done\")\n","\n","    baseline_encoders[city] = {\n","        \"dgi\": dgi_enc,\n","        \"infograph\": infograph_enc,\n","        \"gcl\": gcl_enc,\n","        \"joao\": joao_enc,\n","        \"simgrace\": simgrace_enc,\n","    }\n","\n","print(\"\\n✅ All baseline encoders trained and stored in `baseline_encoders`.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PrNWXCm_ADku","executionInfo":{"status":"ok","timestamp":1747655687152,"user_tz":-60,"elapsed":64588,"user":{"displayName":"Nero Li","userId":"16312290114531733443"}},"outputId":"8e704f54-24e3-473d-b73c-f8ee119097cd"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","===== Training baselines for Chicago (using sample 21) =====\n","  Loading from /content/drive/MyDrive/FractalGCL/city/data/Chicago-share_data/processed_21/data_list.pt\n","  • 100 graphs, feature-dim = 9\n","  ⏳ DGI… [DGI] 1/20 — Loss: 0.6804\n","[DGI] 2/20 — Loss: 0.6571\n","[DGI] 3/20 — Loss: 0.6267\n","[DGI] 4/20 — Loss: 0.6091\n","[DGI] 5/20 — Loss: 0.6177\n","[DGI] 6/20 — Loss: 0.5842\n","[DGI] 7/20 — Loss: 0.6099\n","[DGI] 8/20 — Loss: 0.5979\n","[DGI] 9/20 — Loss: 0.6018\n","[DGI] 10/20 — Loss: 0.5566\n","[DGI] 11/20 — Loss: 0.5755\n","[DGI] 12/20 — Loss: 0.5710\n","[DGI] 13/20 — Loss: 0.5768\n","[DGI] 14/20 — Loss: 0.5445\n","[DGI] 15/20 — Loss: 0.5717\n","[DGI] 16/20 — Loss: 0.5618\n","[DGI] 17/20 — Loss: 0.5715\n","[DGI] 18/20 — Loss: 0.5604\n","[DGI] 19/20 — Loss: 0.5574\n","[DGI] 20/20 — Loss: 0.5714\n","done\n","  ⏳ InfoGraph… [InfoGraph] 1/20 — Loss: 2.9411\n","[InfoGraph] 2/20 — Loss: 2.9197\n","[InfoGraph] 3/20 — Loss: 2.8516\n","[InfoGraph] 4/20 — Loss: 2.8640\n","[InfoGraph] 5/20 — Loss: 2.6996\n","[InfoGraph] 6/20 — Loss: 2.8135\n","[InfoGraph] 7/20 — Loss: 2.7655\n","[InfoGraph] 8/20 — Loss: 2.7830\n","[InfoGraph] 9/20 — Loss: 2.7046\n","[InfoGraph] 10/20 — Loss: 2.7109\n","[InfoGraph] 11/20 — Loss: 2.7292\n","[InfoGraph] 12/20 — Loss: 2.7105\n","[InfoGraph] 13/20 — Loss: 2.6985\n","[InfoGraph] 14/20 — Loss: 2.7303\n","[InfoGraph] 15/20 — Loss: 2.7184\n","[InfoGraph] 16/20 — Loss: 2.7716\n","[InfoGraph] 17/20 — Loss: 2.7752\n","[InfoGraph] 18/20 — Loss: 2.6971\n","[InfoGraph] 19/20 — Loss: 2.6844\n","[InfoGraph] 20/20 — Loss: 2.6709\n","done\n","  ⏳ GCL… [GCL] 1/20 — Loss: 2.8984\n","[GCL] 2/20 — Loss: 2.8168\n","[GCL] 3/20 — Loss: 2.6659\n","[GCL] 4/20 — Loss: 2.6333\n","[GCL] 5/20 — Loss: 2.3877\n","[GCL] 6/20 — Loss: 2.2709\n","[GCL] 7/20 — Loss: 2.3069\n","[GCL] 8/20 — Loss: 2.2962\n","[GCL] 9/20 — Loss: 2.3556\n","[GCL] 10/20 — Loss: 2.2751\n","[GCL] 11/20 — Loss: 2.4189\n","[GCL] 12/20 — Loss: 2.2778\n","[GCL] 13/20 — Loss: 2.2742\n","[GCL] 14/20 — Loss: 2.2436\n","[GCL] 15/20 — Loss: 2.2513\n","[GCL] 16/20 — Loss: 2.2369\n","[GCL] 17/20 — Loss: 2.2258\n","[GCL] 18/20 — Loss: 2.3331\n","[GCL] 19/20 — Loss: 2.1748\n","[GCL] 20/20 — Loss: 2.0861\n","done\n","  ⏳ JOAO… [JOAO] 1/20 — Loss: 2.9456\n","[JOAO] 2/20 — Loss: 2.9449\n","[JOAO] 3/20 — Loss: 2.9442\n","[JOAO] 4/20 — Loss: 2.9406\n","[JOAO] 5/20 — Loss: 2.9385\n","[JOAO] 6/20 — Loss: 2.9305\n","[JOAO] 7/20 — Loss: 2.9311\n","[JOAO] 8/20 — Loss: 2.9296\n","[JOAO] 9/20 — Loss: 2.9229\n","[JOAO] 10/20 — Loss: 2.9191\n","[JOAO] 11/20 — Loss: 2.9163\n","[JOAO] 12/20 — Loss: 2.9203\n","[JOAO] 13/20 — Loss: 2.9126\n","[JOAO] 14/20 — Loss: 2.9109\n","[JOAO] 15/20 — Loss: 2.9105\n","[JOAO] 16/20 — Loss: 2.8999\n","[JOAO] 17/20 — Loss: 2.9093\n","[JOAO] 18/20 — Loss: 2.9101\n","[JOAO] 19/20 — Loss: 2.9110\n","[JOAO] 20/20 — Loss: 2.9009\n","done\n","  ⏳ SimGRACE… [SimGRACE] 1/20 — Loss: 2.9316\n","[SimGRACE] 2/20 — Loss: 2.8736\n","[SimGRACE] 3/20 — Loss: 2.8548\n","[SimGRACE] 4/20 — Loss: 2.7510\n","[SimGRACE] 5/20 — Loss: 2.6298\n","[SimGRACE] 6/20 — Loss: 2.6033\n","[SimGRACE] 7/20 — Loss: 2.4681\n","[SimGRACE] 8/20 — Loss: 2.3141\n","[SimGRACE] 9/20 — Loss: 2.4003\n","[SimGRACE] 10/20 — Loss: 2.2791\n","[SimGRACE] 11/20 — Loss: 2.3866\n","[SimGRACE] 12/20 — Loss: 2.3584\n","[SimGRACE] 13/20 — Loss: 2.2362\n","[SimGRACE] 14/20 — Loss: 2.2311\n","[SimGRACE] 15/20 — Loss: 2.1638\n","[SimGRACE] 16/20 — Loss: 2.3359\n","[SimGRACE] 17/20 — Loss: 2.3910\n","[SimGRACE] 18/20 — Loss: 2.4555\n","[SimGRACE] 19/20 — Loss: 2.2884\n","[SimGRACE] 20/20 — Loss: 2.2436\n","done\n","\n","===== Training baselines for SF (using sample 32) =====\n","  Loading from /content/drive/MyDrive/FractalGCL/city/data/SF-share_data/processed_32/data_list.pt\n","  • 100 graphs, feature-dim = 7\n","  ⏳ DGI… [DGI] 1/20 — Loss: 0.6678\n","[DGI] 2/20 — Loss: 0.6081\n","[DGI] 3/20 — Loss: 0.5556\n","[DGI] 4/20 — Loss: 0.5291\n","[DGI] 5/20 — Loss: 0.4867\n","[DGI] 6/20 — Loss: 0.4784\n","[DGI] 7/20 — Loss: 0.4738\n","[DGI] 8/20 — Loss: 0.4795\n","[DGI] 9/20 — Loss: 0.4569\n","[DGI] 10/20 — Loss: 0.4658\n","[DGI] 11/20 — Loss: 0.4446\n","[DGI] 12/20 — Loss: 0.4224\n","[DGI] 13/20 — Loss: 0.4347\n","[DGI] 14/20 — Loss: 0.4107\n","[DGI] 15/20 — Loss: 0.4431\n","[DGI] 16/20 — Loss: 0.4341\n","[DGI] 17/20 — Loss: 0.4149\n","[DGI] 18/20 — Loss: 0.4155\n","[DGI] 19/20 — Loss: 0.3864\n","[DGI] 20/20 — Loss: 0.4021\n","done\n","  ⏳ InfoGraph… [InfoGraph] 1/20 — Loss: 2.9337\n","[InfoGraph] 2/20 — Loss: 2.8716\n","[InfoGraph] 3/20 — Loss: 2.8428\n","[InfoGraph] 4/20 — Loss: 2.8432\n","[InfoGraph] 5/20 — Loss: 2.8163\n","[InfoGraph] 6/20 — Loss: 2.8297\n","[InfoGraph] 7/20 — Loss: 2.8142\n","[InfoGraph] 8/20 — Loss: 2.8294\n","[InfoGraph] 9/20 — Loss: 2.8098\n","[InfoGraph] 10/20 — Loss: 2.7985\n","[InfoGraph] 11/20 — Loss: 2.7667\n","[InfoGraph] 12/20 — Loss: 2.7660\n","[InfoGraph] 13/20 — Loss: 2.7603\n","[InfoGraph] 14/20 — Loss: 2.8121\n","[InfoGraph] 15/20 — Loss: 2.7780\n","[InfoGraph] 16/20 — Loss: 2.7739\n","[InfoGraph] 17/20 — Loss: 2.7770\n","[InfoGraph] 18/20 — Loss: 2.7657\n","[InfoGraph] 19/20 — Loss: 2.7227\n","[InfoGraph] 20/20 — Loss: 2.7423\n","done\n","  ⏳ GCL… [GCL] 1/20 — Loss: 2.8915\n","[GCL] 2/20 — Loss: 2.7661\n","[GCL] 3/20 — Loss: 2.6540\n","[GCL] 4/20 — Loss: 2.3961\n","[GCL] 5/20 — Loss: 2.2583\n","[GCL] 6/20 — Loss: 2.1344\n","[GCL] 7/20 — Loss: 2.1556\n","[GCL] 8/20 — Loss: 2.0993\n","[GCL] 9/20 — Loss: 2.2741\n","[GCL] 10/20 — Loss: 2.1701\n","[GCL] 11/20 — Loss: 2.2212\n","[GCL] 12/20 — Loss: 2.2251\n","[GCL] 13/20 — Loss: 2.1245\n","[GCL] 14/20 — Loss: 2.0594\n","[GCL] 15/20 — Loss: 2.0518\n","[GCL] 16/20 — Loss: 2.0748\n","[GCL] 17/20 — Loss: 2.0149\n","[GCL] 18/20 — Loss: 2.0702\n","[GCL] 19/20 — Loss: 2.0961\n","[GCL] 20/20 — Loss: 2.0852\n","done\n","  ⏳ JOAO… [JOAO] 1/20 — Loss: 2.9456\n","[JOAO] 2/20 — Loss: 2.9441\n","[JOAO] 3/20 — Loss: 2.9417\n","[JOAO] 4/20 — Loss: 2.9357\n","[JOAO] 5/20 — Loss: 2.9284\n","[JOAO] 6/20 — Loss: 2.9246\n","[JOAO] 7/20 — Loss: 2.9178\n","[JOAO] 8/20 — Loss: 2.9143\n","[JOAO] 9/20 — Loss: 2.9100\n","[JOAO] 10/20 — Loss: 2.9087\n","[JOAO] 11/20 — Loss: 2.8991\n","[JOAO] 12/20 — Loss: 2.9073\n","[JOAO] 13/20 — Loss: 2.8977\n","[JOAO] 14/20 — Loss: 2.8938\n","[JOAO] 15/20 — Loss: 2.8851\n","[JOAO] 16/20 — Loss: 2.8801\n","[JOAO] 17/20 — Loss: 2.8914\n","[JOAO] 18/20 — Loss: 2.8721\n","[JOAO] 19/20 — Loss: 2.8766\n","[JOAO] 20/20 — Loss: 2.8953\n","done\n","  ⏳ SimGRACE… [SimGRACE] 1/20 — Loss: 2.9201\n","[SimGRACE] 2/20 — Loss: 2.8682\n","[SimGRACE] 3/20 — Loss: 2.7592\n","[SimGRACE] 4/20 — Loss: 2.5938\n","[SimGRACE] 5/20 — Loss: 2.3371\n","[SimGRACE] 6/20 — Loss: 2.4149\n","[SimGRACE] 7/20 — Loss: 2.1998\n","[SimGRACE] 8/20 — Loss: 2.2023\n","[SimGRACE] 9/20 — Loss: 2.1627\n","[SimGRACE] 10/20 — Loss: 2.1717\n","[SimGRACE] 11/20 — Loss: 2.2647\n","[SimGRACE] 12/20 — Loss: 2.0955\n","[SimGRACE] 13/20 — Loss: 2.0737\n","[SimGRACE] 14/20 — Loss: 2.1098\n","[SimGRACE] 15/20 — Loss: 1.9978\n","[SimGRACE] 16/20 — Loss: 2.0664\n","[SimGRACE] 17/20 — Loss: 2.0216\n","[SimGRACE] 18/20 — Loss: 2.0590\n","[SimGRACE] 19/20 — Loss: 2.0281\n","[SimGRACE] 20/20 — Loss: 1.9891\n","done\n","\n","===== Training baselines for NY (using sample 33) =====\n","  Loading from /content/drive/MyDrive/FractalGCL/city/data/NY-share_data/processed_33/data_list.pt\n","  • 100 graphs, feature-dim = 10\n","  ⏳ DGI… [DGI] 1/20 — Loss: 0.6668\n","[DGI] 2/20 — Loss: 0.6237\n","[DGI] 3/20 — Loss: 0.5821\n","[DGI] 4/20 — Loss: 0.5606\n","[DGI] 5/20 — Loss: 0.5395\n","[DGI] 6/20 — Loss: 0.5423\n","[DGI] 7/20 — Loss: 0.5384\n","[DGI] 8/20 — Loss: 0.5080\n","[DGI] 9/20 — Loss: 0.5214\n","[DGI] 10/20 — Loss: 0.5119\n","[DGI] 11/20 — Loss: 0.4984\n","[DGI] 12/20 — Loss: 0.4858\n","[DGI] 13/20 — Loss: 0.5091\n","[DGI] 14/20 — Loss: 0.4761\n","[DGI] 15/20 — Loss: 0.5184\n","[DGI] 16/20 — Loss: 0.4796\n","[DGI] 17/20 — Loss: 0.5197\n","[DGI] 18/20 — Loss: 0.4847\n","[DGI] 19/20 — Loss: 0.4809\n","[DGI] 20/20 — Loss: 0.5083\n","done\n","  ⏳ InfoGraph… [InfoGraph] 1/20 — Loss: 2.9404\n","[InfoGraph] 2/20 — Loss: 2.9087\n","[InfoGraph] 3/20 — Loss: 2.7903\n","[InfoGraph] 4/20 — Loss: 2.8218\n","[InfoGraph] 5/20 — Loss: 2.8228\n","[InfoGraph] 6/20 — Loss: 2.8132\n","[InfoGraph] 7/20 — Loss: 2.7943\n","[InfoGraph] 8/20 — Loss: 2.7819\n","[InfoGraph] 9/20 — Loss: 2.7768\n","[InfoGraph] 10/20 — Loss: 2.7411\n","[InfoGraph] 11/20 — Loss: 2.7451\n","[InfoGraph] 12/20 — Loss: 2.7748\n","[InfoGraph] 13/20 — Loss: 2.6876\n","[InfoGraph] 14/20 — Loss: 2.7458\n","[InfoGraph] 15/20 — Loss: 2.7094\n","[InfoGraph] 16/20 — Loss: 2.7469\n","[InfoGraph] 17/20 — Loss: 2.6714\n","[InfoGraph] 18/20 — Loss: 2.7103\n","[InfoGraph] 19/20 — Loss: 2.7239\n","[InfoGraph] 20/20 — Loss: 2.7109\n","done\n","  ⏳ GCL… [GCL] 1/20 — Loss: 2.9142\n","[GCL] 2/20 — Loss: 2.8485\n","[GCL] 3/20 — Loss: 2.6639\n","[GCL] 4/20 — Loss: 2.4876\n","[GCL] 5/20 — Loss: 2.2312\n","[GCL] 6/20 — Loss: 2.2641\n","[GCL] 7/20 — Loss: 2.2114\n","[GCL] 8/20 — Loss: 2.2874\n","[GCL] 9/20 — Loss: 2.1911\n","[GCL] 10/20 — Loss: 2.2278\n","[GCL] 11/20 — Loss: 2.2285\n","[GCL] 12/20 — Loss: 2.1982\n","[GCL] 13/20 — Loss: 2.1910\n","[GCL] 14/20 — Loss: 2.1734\n","[GCL] 15/20 — Loss: 2.2174\n","[GCL] 16/20 — Loss: 2.2047\n","[GCL] 17/20 — Loss: 2.1624\n","[GCL] 18/20 — Loss: 2.1823\n","[GCL] 19/20 — Loss: 2.1248\n","[GCL] 20/20 — Loss: 2.1345\n","done\n","  ⏳ JOAO… [JOAO] 1/20 — Loss: 2.9454\n","[JOAO] 2/20 — Loss: 2.9443\n","[JOAO] 3/20 — Loss: 2.9412\n","[JOAO] 4/20 — Loss: 2.9345\n","[JOAO] 5/20 — Loss: 2.9299\n","[JOAO] 6/20 — Loss: 2.9255\n","[JOAO] 7/20 — Loss: 2.9242\n","[JOAO] 8/20 — Loss: 2.9195\n","[JOAO] 9/20 — Loss: 2.9248\n","[JOAO] 10/20 — Loss: 2.9249\n","[JOAO] 11/20 — Loss: 2.9165\n","[JOAO] 12/20 — Loss: 2.9093\n","[JOAO] 13/20 — Loss: 2.9072\n","[JOAO] 14/20 — Loss: 2.9018\n","[JOAO] 15/20 — Loss: 2.9039\n","[JOAO] 16/20 — Loss: 2.8944\n","[JOAO] 17/20 — Loss: 2.8860\n","[JOAO] 18/20 — Loss: 2.8891\n","[JOAO] 19/20 — Loss: 2.8796\n","[JOAO] 20/20 — Loss: 2.8738\n","done\n","  ⏳ SimGRACE… [SimGRACE] 1/20 — Loss: 2.9066\n","[SimGRACE] 2/20 — Loss: 2.8003\n","[SimGRACE] 3/20 — Loss: 2.6668\n","[SimGRACE] 4/20 — Loss: 2.4744\n","[SimGRACE] 5/20 — Loss: 2.2789\n","[SimGRACE] 6/20 — Loss: 2.2060\n","[SimGRACE] 7/20 — Loss: 2.3375\n","[SimGRACE] 8/20 — Loss: 2.3086\n","[SimGRACE] 9/20 — Loss: 2.2148\n","[SimGRACE] 10/20 — Loss: 2.2397\n","[SimGRACE] 11/20 — Loss: 2.2504\n","[SimGRACE] 12/20 — Loss: 2.2595\n","[SimGRACE] 13/20 — Loss: 2.1989\n","[SimGRACE] 14/20 — Loss: 2.1839\n","[SimGRACE] 15/20 — Loss: 2.2044\n","[SimGRACE] 16/20 — Loss: 2.1948\n","[SimGRACE] 17/20 — Loss: 2.2255\n","[SimGRACE] 18/20 — Loss: 2.2148\n","[SimGRACE] 19/20 — Loss: 2.2660\n","[SimGRACE] 20/20 — Loss: 2.3760\n","done\n","\n","✅ All baseline encoders trained and stored in `baseline_encoders`.\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","import torch\n","import networkx as nx\n","import pandas as pd\n","from torch_geometric.utils import to_networkx\n","\n","# Cities to process\n","cities = [\"Chicago\", \"SF\", \"NY\"]\n","\n","# ─── Hyperparameters ─────────────────────────────────────────────\n","batch_size      = 16\n","hidden_channels = 64\n","num_layers      = 2\n","embed_dim       = 128\n","drop_prob       = 0.1\n","alpha           = 0.4\n","renorm_radius   = 1.0\n","fractal_epochs  = 20\n","lr              = 1e-3\n","# ─────────────────────────────────────────────────────────────────\n","\n","# Mount Google Drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","fractal_encoders = {}\n","for city in cities:\n","    print(f\"\\n===== Training FractalGCL for {city} =====\")\n","    paths      = get_file_paths(city)\n","    # full_list  = torch.load(f\"{paths['save_path']}/data_list.pt\", weights_only=False)\n","    full_list = torch.load(f\"/content/drive/MyDrive/FractalGCL/city/data/{city}-share_data/processed_{sample_id}/data_list.pt\",weights_only=False)\n","    # df         = pd.read_csv(f\"{paths['save_path']}/feature_data.csv\")\n","    df = pd.read_csv(f\"/content/drive/MyDrive/FractalGCL/city/data/{city}-share_data/processed_{sample_id}/feature_data.csv\")\n","    median_acc = df['total_accidents'].median()\n","    y_full     = (df['total_accidents'] > median_acc).astype(int).values\n","\n","    # Align lengths\n","    n_graphs  = min(len(full_list), len(y_full))\n","    data_list = full_list[:n_graphs]\n","    print(f\"{city}: {n_graphs} graphs\")\n","\n","    # Compute diameter & box dimension\n","    diameters, dims = [], []\n","    for d in data_list:\n","        G = to_networkx(d, to_undirected=True)\n","        if not nx.is_connected(G):\n","            G = G.subgraph(max(nx.connected_components(G), key=len)).copy()\n","        diameters.append(nx.diameter(G))\n","        dims.append(compute_box_dim(G)[1])\n","\n","    # Pad / trim features to a uniform dimension\n","    fractal_in_dim = data_list[0].x.size(1)\n","    def pad_trim(dl, dim):\n","        for d in dl:\n","            x, diff = d.x, dim - d.x.size(1)\n","            if diff > 0:\n","                pad = torch.zeros(x.size(0), diff, device=x.device)\n","                d.x = torch.cat([x, pad], dim=1)\n","            elif diff < 0:\n","                d.x = x[:, :dim]\n","        return dl\n","    data_list = pad_trim(data_list, fractal_in_dim)\n","\n","    # Train FractalGCL\n","    fractal_enc = train_fractal(\n","        data_list, fractal_in_dim, diameters, dims,\n","        hidden_channels, num_layers, embed_dim,\n","        alpha=alpha, renorm_r=renorm_radius,\n","        lr=lr, epochs=fractal_epochs, batch_size=batch_size,\n","        drop_prob=drop_prob\n","    )\n","    fractal_enc.eval()\n","    fractal_encoders[city] = fractal_enc\n","\n","# Save all models to disk (e.g., with pickle)\n","import pickle\n","with open('/content/drive/MyDrive/fractal_encoders.pkl', 'wb') as f:\n","    pickle.dump(fractal_encoders, f)\n","print(\"\\n✅ FractalGCL models have been trained and saved.\")\n"],"metadata":{"id":"RBceL2asVHt_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747656638683,"user_tz":-60,"elapsed":872880,"user":{"displayName":"Nero Li","userId":"16312290114531733443"}},"outputId":"d3cc7083-e159-4aae-fd28-8c383bd625ac"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","\n","===== Training FractalGCL for Chicago =====\n","Chicago: 100 graphs\n","[Fractal] Epoch 1/20  Loss = 2.5871\n","[Fractal] Epoch 2/20  Loss = 2.5127\n","[Fractal] Epoch 3/20  Loss = 2.2753\n","[Fractal] Epoch 4/20  Loss = 2.0797\n","[Fractal] Epoch 5/20  Loss = 2.0905\n","[Fractal] Epoch 6/20  Loss = 2.0343\n","[Fractal] Epoch 7/20  Loss = 2.0291\n","[Fractal] Epoch 8/20  Loss = 1.9891\n","[Fractal] Epoch 9/20  Loss = 2.2122\n","[Fractal] Epoch 10/20  Loss = 2.0388\n","[Fractal] Epoch 11/20  Loss = 2.0781\n","[Fractal] Epoch 12/20  Loss = 2.0003\n","[Fractal] Epoch 13/20  Loss = 1.8624\n","[Fractal] Epoch 14/20  Loss = 1.9165\n","[Fractal] Epoch 15/20  Loss = 1.8333\n","[Fractal] Epoch 16/20  Loss = 1.8551\n","[Fractal] Epoch 17/20  Loss = 1.7560\n","[Fractal] Epoch 18/20  Loss = 1.8686\n","[Fractal] Epoch 19/20  Loss = 1.7209\n","[Fractal] Epoch 20/20  Loss = 1.6942\n","\n","===== Training FractalGCL for SF =====\n","SF: 100 graphs\n","[Fractal] Epoch 1/20  Loss = 2.5492\n","[Fractal] Epoch 2/20  Loss = 2.3646\n","[Fractal] Epoch 3/20  Loss = 1.9510\n","[Fractal] Epoch 4/20  Loss = 1.8003\n","[Fractal] Epoch 5/20  Loss = 1.7438\n","[Fractal] Epoch 6/20  Loss = 1.7027\n","[Fractal] Epoch 7/20  Loss = 1.6601\n","[Fractal] Epoch 8/20  Loss = 1.6747\n","[Fractal] Epoch 9/20  Loss = 1.6372\n","[Fractal] Epoch 10/20  Loss = 1.6773\n","[Fractal] Epoch 11/20  Loss = 1.5796\n","[Fractal] Epoch 12/20  Loss = 1.6663\n","[Fractal] Epoch 13/20  Loss = 1.5652\n","[Fractal] Epoch 14/20  Loss = 1.7084\n","[Fractal] Epoch 15/20  Loss = 1.6918\n","[Fractal] Epoch 16/20  Loss = 1.5843\n","[Fractal] Epoch 17/20  Loss = 1.6648\n","[Fractal] Epoch 18/20  Loss = 1.6100\n","[Fractal] Epoch 19/20  Loss = 1.6623\n","[Fractal] Epoch 20/20  Loss = 1.6029\n","\n","===== Training FractalGCL for NY =====\n","NY: 100 graphs\n","[Fractal] Epoch 1/20  Loss = 2.5095\n","[Fractal] Epoch 2/20  Loss = 2.3020\n","[Fractal] Epoch 3/20  Loss = 2.0157\n","[Fractal] Epoch 4/20  Loss = 1.9166\n","[Fractal] Epoch 5/20  Loss = 1.9381\n","[Fractal] Epoch 6/20  Loss = 1.9087\n","[Fractal] Epoch 7/20  Loss = 1.8618\n","[Fractal] Epoch 8/20  Loss = 1.8119\n","[Fractal] Epoch 9/20  Loss = 1.8143\n","[Fractal] Epoch 10/20  Loss = 1.8405\n","[Fractal] Epoch 11/20  Loss = 1.7837\n","[Fractal] Epoch 12/20  Loss = 1.7962\n","[Fractal] Epoch 13/20  Loss = 1.7410\n","[Fractal] Epoch 14/20  Loss = 1.6930\n","[Fractal] Epoch 15/20  Loss = 1.7301\n","[Fractal] Epoch 16/20  Loss = 1.8086\n","[Fractal] Epoch 17/20  Loss = 1.6437\n","[Fractal] Epoch 18/20  Loss = 1.5932\n","[Fractal] Epoch 19/20  Loss = 1.6029\n","[Fractal] Epoch 20/20  Loss = 1.6388\n","\n","✅ FractalGCL models have been trained and saved.\n"]}]},{"cell_type":"code","source":["from gis_utils import get_file_paths\n","import pandas as pd\n","import numpy as np\n","import torch\n","from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n","from sklearn.linear_model import SGDClassifier\n","\n","# Automatically adjust the number of folds; skip the city-task pair if samples are insufficient\n","def evaluate_with_auto_splits(\n","    X, y,\n","    n_splits=10,\n","    n_repeats=1000,\n","    random_state=42,\n","    classifier=None\n","):\n","    \"\"\"\n","    Perform repeated stratified k-fold evaluation with an adaptive number of splits.\n","    Returns (mean_acc, std_acc) rounded to 4 decimals, or None if the task is skipped.\n","    \"\"\"\n","    counts = np.bincount(y)\n","    min_count = counts[counts > 0].min()\n","    n_splits_adj = min(n_splits, min_count)\n","    if n_splits_adj < 2:\n","        return None                     # Not enough samples, skip\n","    if classifier is None:\n","        classifier = SGDClassifier(\n","            loss='hinge',\n","            max_iter=1000,\n","            tol=1e-3,\n","            random_state=random_state\n","        )\n","\n","    rkf = RepeatedStratifiedKFold(\n","        n_splits=n_splits_adj,\n","        n_repeats=n_repeats,\n","        random_state=random_state\n","    )\n","    scores = cross_val_score(\n","        classifier, X, y,\n","        cv=rkf,\n","        scoring='accuracy',\n","        n_jobs=-1\n","    )\n","    return round(scores.mean(), 4), round(scores.std(), 4)\n","\n","\n","# Assume these are already in memory:\n","# baseline_encoders = {\"Chicago\": {...}, \"SF\": {...}, \"NY\": {...}}\n","# fractal_encoders  = {\"Chicago\": enc_chi, \"SF\": enc_sf, \"NY\": enc_ny}\n","# extract_embeddings(enc, data_list) is defined elsewhere\n","\n","cities = [\"Chicago\", \"SF\", \"NY\"]\n","model_names = list(baseline_encoders[cities[0]].keys()) + [\"FractalGCL\"]\n","\n","# Accident-related downstream tasks\n","tasks = {\n","    # 0. Total accident volume: high vs. low (binary)\n","    \"total_accidents_high\": lambda df: df['total_accidents']\n","        .gt(df['total_accidents'].median()).astype(int),\n","\n","    # 1. Accident volume level: low / mid / high (three-class)\n","    \"accident_volume_level\": lambda df: pd.cut(\n","        df['total_accidents'],\n","        bins=[-1,\n","              df['total_accidents'].quantile(0.33),\n","              df['total_accidents'].quantile(0.67),\n","              df['total_accidents'].max()],\n","        labels=[0, 1, 2]\n","    ).astype(int),\n","\n","    # 2. Entropy of severity distribution: high vs. low (binary)\n","    \"severity_entropy\": lambda df: (\n","        pd.concat([\n","            df[['severity_1', 'severity_2', 'severity_3', 'severity_4']]\n","              .div(df['total_accidents'], axis=0)\n","              .replace(0, np.nan)\n","              .apply(lambda row: -np.nansum(row * np.log(row)), axis=1)\n","        ], axis=1).iloc[:, 0]\n","        .gt(pd.concat([\n","            df[['severity_1', 'severity_2', 'severity_3', 'severity_4']]\n","              .div(df['total_accidents'], axis=0)\n","              .replace(0, np.nan)\n","              .apply(lambda row: -np.nansum(row * np.log(row)), axis=1)\n","        ], axis=1).iloc[:, 0].median())\n","        .astype(int)\n","    ),\n","\n","    # 3. Presence of severity-3 accidents (binary)\n","    \"has_sev3\": lambda df: (df['severity_3'] > 0).astype(int),\n","\n","    # 4. Presence of severity-4 accidents (binary)\n","    \"has_sev4\": lambda df: (df['severity_4'] > 0).astype(int),\n","\n","    # 5. Composite risk level: low / mid / high (three-class)\n","    #    High risk: total > median  &  (sev3+sev4)/total > median  → 2\n","    #    Low  risk: total ≤ median &  (sev3+sev4)/total ≤ median  → 0\n","    #    Mid  risk: otherwise                                      → 1\n","    \"risk_level\": lambda df: (\n","        pd.Series(np.where(\n","            (df['total_accidents'] > df['total_accidents'].median()) &\n","            (((df['severity_3'] + df['severity_4']) / df['total_accidents'])\n","              > ((df['severity_3'] + df['severity_4']) / df['total_accidents']).median()),\n","            2,\n","            np.where(\n","                (df['total_accidents'] <= df['total_accidents'].median()) &\n","                (((df['severity_3'] + df['severity_4']) / df['total_accidents'])\n","                  <= ((df['severity_3'] + df['severity_4']) / df['total_accidents']).median()),\n","                0, 1\n","            )\n","        ), index=df.index).astype(int)\n","    )\n","}\n","\n","# Aggregate and print results by task\n","for task_name, label_fn in tasks.items():\n","    print(f\"\\n===== Task: {task_name} =====\")\n","    for city in cities:\n","        paths     = get_file_paths(city)\n","        # df        = pd.read_csv(f\"{paths['save_path']}/feature_data.csv\")\n","\n","        df = pd.read_csv(f\"/content/drive/MyDrive/FractalGCL/city/data/{city}-share_data/processed_{sample_id}/feature_data.csv\")\n","\n","        # data_list = torch.load(f\"{paths['save_path']}/data_list.pt\", weights_only=False)\n","\n","        data_list = torch.load(f\"/content/drive/MyDrive/FractalGCL/city/data/{city}-share_data/processed_{sample_id}/data_list.pt\",weights_only=False)\n","\n","        # Build labels; skip if construction fails or only one class exists\n","        try:\n","            y = label_fn(df)\n","        except Exception as e:\n","            print(f\"{city}: failed to build labels ({e}), skipped\")\n","            continue\n","        if y.nunique() < 2:\n","            print(f\"{city}: num_classes = {y.nunique()} (insufficient), skipped\")\n","            continue\n","\n","        # Align sample counts\n","        n = min(len(data_list), len(y))\n","        data_list = data_list[:n]\n","        y = y.values[:n]\n","\n","        # Extract embeddings and evaluate\n","        results = {}\n","        for name in model_names:\n","            enc = baseline_encoders[city].get(name) or fractal_encoders[city]\n","            X = extract_embeddings(enc, data_list)\n","            res = evaluate_with_auto_splits(X[:n], y)\n","            if res is not None:\n","                results[name] = res\n","\n","        # Print per-city results\n","        if results:\n","            line = city + \": \" + \", \".join(\n","                f\"{m} {results[m][0]:.4f}±{results[m][1]:.4f}\"\n","                for m in model_names if m in results\n","            )\n","            print(line)\n","        else:\n","            print(f\"{city}: no model evaluated or all skipped\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LRooN19_zApP","executionInfo":{"status":"ok","timestamp":1747657634681,"user_tz":-60,"elapsed":660813,"user":{"displayName":"Nero Li","userId":"16312290114531733443"}},"outputId":"3026391f-d471-401f-a591-81eefc706711"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","===== Task: total_accidents_high =====\n","Chicago: dgi 0.5389±0.1047, infograph 0.5312±0.0979, gcl 0.5596±0.1227, joao 0.5390±0.1186, simgrace 0.5644±0.1239, FractalGCL 0.6094±0.1382\n","SF: dgi 0.7322±0.1380, infograph 0.7585±0.1328, gcl 0.7778±0.1296, joao 0.7631±0.1446, simgrace 0.7790±0.1303, FractalGCL 0.7736±0.1287\n","NY: dgi 0.5065±0.0550, infograph 0.5338±0.0898, gcl 0.5876±0.1269, joao 0.5050±0.1011, simgrace 0.5117±0.1159, FractalGCL 0.6418±0.1288\n","\n","===== Task: accident_volume_level =====\n","Chicago: dgi 0.3998±0.1134, infograph 0.4133±0.1184, gcl 0.4878±0.1434, joao 0.4118±0.1267, simgrace 0.4665±0.1329, FractalGCL 0.5656±0.1476\n","SF: dgi 0.5813±0.1269, infograph 0.5955±0.1240, gcl 0.6042±0.1240, joao 0.5790±0.1158, simgrace 0.6049±0.1233, FractalGCL 0.6044±0.1278\n","NY: dgi 0.3484±0.0926, infograph 0.3479±0.0906, gcl 0.3901±0.1298, joao 0.3414±0.1099, simgrace 0.3388±0.1186, FractalGCL 0.4205±0.1286\n","\n","===== Task: severity_entropy =====\n","Chicago: dgi 0.4964±0.0553, infograph 0.4958±0.0598, gcl 0.5496±0.1206, joao 0.5054±0.0948, simgrace 0.5492±0.1149, FractalGCL 0.6343±0.1358\n","SF: dgi 0.4894±0.0507, infograph 0.4905±0.0579, gcl 0.4856±0.1080, joao 0.4934±0.0922, simgrace 0.4881±0.1061, FractalGCL 0.4907±0.1155\n","NY: dgi 0.5068±0.0651, infograph 0.5217±0.0862, gcl 0.5456±0.1221, joao 0.5078±0.1087, simgrace 0.5114±0.1225, FractalGCL 0.5575±0.1224\n","\n","===== Task: has_sev3 =====\n","Chicago: dgi 0.6093±0.1819, infograph 0.6021±0.1843, gcl 0.6424±0.1733, joao 0.6110±0.1700, simgrace 0.6175±0.1681, FractalGCL 0.6674±0.1527\n","SF: dgi 0.9344±0.1022, infograph 0.9291±0.0958, gcl 0.9281±0.0851, joao 0.9246±0.1064, simgrace 0.9322±0.0780, FractalGCL 0.9240±0.0806\n","NY: dgi 0.6092±0.1601, infograph 0.6148±0.1605, gcl 0.6240±0.1460, joao 0.5941±0.1595, simgrace 0.5972±0.1608, FractalGCL 0.6650±0.1321\n","\n","===== Task: has_sev4 =====\n","Chicago: dgi 0.5307±0.1003, infograph 0.5339±0.1050, gcl 0.5808±0.1216, joao 0.5411±0.1195, simgrace 0.5968±0.1417, FractalGCL 0.6392±0.1373\n","SF: dgi 0.5453±0.1294, infograph 0.5545±0.1381, gcl 0.5550±0.1409, joao 0.5367±0.1247, simgrace 0.5534±0.1384, FractalGCL 0.5562±0.1436\n","NY: dgi 0.5055±0.0851, infograph 0.5035±0.0929, gcl 0.5142±0.1227, joao 0.5078±0.1233, simgrace 0.5029±0.1287, FractalGCL 0.5220±0.1136\n","\n","===== Task: risk_level =====\n","Chicago: dgi 0.3534±0.0919, infograph 0.3488±0.0890, gcl 0.3933±0.1257, joao 0.3640±0.1157, simgrace 0.4276±0.1353, FractalGCL 0.4814±0.1370\n","SF: dgi 0.4226±0.1348, infograph 0.4239±0.1381, gcl 0.4382±0.1358, joao 0.4327±0.1338, simgrace 0.4404±0.1363, FractalGCL 0.4532±0.1374\n","NY: dgi 0.3854±0.1085, infograph 0.3940±0.1139, gcl 0.4579±0.1389, joao 0.3742±0.1222, simgrace 0.3897±0.1302, FractalGCL 0.4957±0.1389\n"]}]},{"cell_type":"code","source":["from gis_utils import get_file_paths\n","import pandas as pd\n","import numpy as np\n","import torch\n","from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n","from sklearn.linear_model import SGDClassifier\n","\n","# Automatically adjust the number of folds; skip the city–task pair if samples are insufficient\n","def evaluate_with_auto_splits(\n","    X, y,\n","    n_splits=10,\n","    n_repeats=1000,\n","    random_state=42,\n","    classifier=None\n","):\n","    counts = np.bincount(y)\n","    min_count = counts[counts > 0].min()\n","    n_splits_adj = min(n_splits, min_count)\n","    if n_splits_adj < 2:\n","        return None                                       # Too few samples → skip\n","    if classifier is None:\n","        classifier = SGDClassifier(\n","            loss='hinge',\n","            max_iter=1000,\n","            tol=1e-3,\n","            random_state=random_state\n","        )\n","    rkf = RepeatedStratifiedKFold(\n","        n_splits=n_splits_adj,\n","        n_repeats=n_repeats,\n","        random_state=random_state\n","    )\n","    scores = cross_val_score(\n","        classifier, X, y,\n","        cv=rkf,\n","        scoring='accuracy',\n","        n_jobs=-1\n","    )\n","    return round(scores.mean(), 4), round(scores.std(), 4)\n","\n","# Assumed to already exist in memory:\n","# baseline_encoders = {\"Chicago\": {...}, \"SF\": {...}, \"NY\": {...}}\n","# fractal_encoders  = {\"Chicago\": enc_chi, \"SF\": enc_sf, \"NY\": enc_ny}\n","# extract_embeddings(enc, data_list) is defined elsewhere\n","\n","cities = [\"Chicago\", \"SF\", \"NY\"]\n","model_names = list(baseline_encoders[cities[0]].keys()) + [\"FractalGCL\"]\n","\n","# Define six non-accident downstream tasks\n","tasks = {\n","    # 1. Dominant land-use function (6-class):\n","    #    office, sustenance, transportation, retail, leisure, residence\n","    \"dominant_poi\": lambda df: df[\n","        ['office_tags', 'sustenance_tags', 'transportation_tags',\n","         'retail_tags', 'leisure_tags', 'residence_tags']\n","    ].idxmax(axis=1).map({\n","        'office_tags': 0, 'sustenance_tags': 1, 'transportation_tags': 2,\n","        'retail_tags': 3, 'leisure_tags': 4, 'residence_tags': 5\n","    }).astype(int),\n","\n","    # 2. POI mix-entropy level (3-class): tertiles of POI entropy\n","    \"poi_entropy_level\": lambda df: pd.qcut(\n","        -np.sum(\n","            (p := df[\n","                ['office_tags', 'sustenance_tags', 'transportation_tags',\n","                 'retail_tags', 'leisure_tags', 'residence_tags']\n","            ].div(\n","                df[\n","                    ['office_tags', 'sustenance_tags', 'transportation_tags',\n","                     'retail_tags', 'leisure_tags', 'residence_tags']\n","                ].sum(axis=1),\n","                axis=0\n","            )).replace(0, 1e-12) * np.log(p),\n","            axis=1\n","        ),\n","        3, labels=[0, 1, 2]\n","    ).astype(int),\n","\n","    # 3. Population-density level (4-class): quartiles of population density\n","    \"pop_density_level\": lambda df: pd.qcut(\n","        df['population_density'], 4, labels=[0, 1, 2, 3]\n","    ).astype(int),\n","\n","    # 4. Function × density combo (12-class):\n","    #    dominant_poi + 6 × (high-pop? 1 : 0)\n","    \"func_density_combo\": lambda df: (\n","        df[\n","            ['office_tags', 'sustenance_tags', 'transportation_tags',\n","             'retail_tags', 'leisure_tags', 'residence_tags']\n","        ].idxmax(axis=1).map({\n","            'office_tags'      : 0, 'sustenance_tags'     : 1,\n","            'transportation_tags': 2, 'retail_tags'       : 3,\n","            'leisure_tags'     : 4, 'residence_tags'      : 5\n","        }).astype(int)\n","        + 6 * (df['population_density'] > df['population_density'].median()).astype(int)\n","    ),\n","\n","    # 5. Night-life hotspot (binary):\n","    #    leisure / residence ratio above median → 1, else 0\n","    \"nightlife_hotspot\": lambda df: (\n","        (df['leisure_tags'] / (df['residence_tags'] + 1e-8))\n","        .gt((df['leisure_tags'] / (df['residence_tags'] + 1e-8)).median())\n","        .astype(int)\n","    ),\n","\n","    # 6. Commercial–residential mix (3-class):\n","    #    tertiles of retail / (retail + residence)\n","    \"commercial_residential_mix\": lambda df: pd.qcut(\n","        df['retail_tags'] / (df['retail_tags'] + df['residence_tags'] + 1e-8),\n","        3, labels=[0, 1, 2]\n","    ).astype(int),\n","}\n","\n","# Evaluate every task and print aggregated results\n","for task_name, label_fn in tasks.items():\n","    print(f\"\\n===== Task: {task_name} =====\")\n","    for city in cities:\n","        paths     = get_file_paths(city)\n","\n","        #  df        = pd.read_csv(f\"{paths['save_path']}/feature_data.csv\")\n","        df = pd.read_csv(f\"/content/drive/MyDrive/FractalGCL/city/data/{city}-share_data/processed_{sample_id}/feature_data.csv\")\n","\n","        # data_list = torch.load(f\"{paths['save_path']}/data_list.pt\", weights_only=False)\n","        data_list = torch.load(f\"/content/drive/MyDrive/FractalGCL/city/data/{city}-share_data/processed_{sample_id}/data_list.pt\",weights_only=False)\n","\n","\n","        # Build labels; skip city if label construction fails or has <2 classes\n","        try:\n","            y = label_fn(df)\n","        except Exception as e:\n","            print(f\"{city}: label construction failed ({e}), skipped\")\n","            continue\n","        if y.nunique() < 2:\n","            print(f\"{city}: num_classes = {y.nunique()} (insufficient), skipped\")\n","            continue\n","\n","        # Align sample counts\n","        n = min(len(data_list), len(y))\n","        data_list = data_list[:n]\n","        y = y.values[:n]\n","\n","        # Extract embeddings and evaluate\n","        results = {}\n","        for name in model_names:\n","            enc = baseline_encoders[city].get(name) or fractal_encoders[city]\n","            X = extract_embeddings(enc, data_list)\n","            res = evaluate_with_auto_splits(X[:n], y)\n","            if res is not None:\n","                results[name] = res\n","\n","        # Print per-city results\n","        if results:\n","            line = city + \": \" + \", \".join(\n","                f\"{m} {results[m][0]:.4f}±{results[m][1]:.4f}\"\n","                for m in model_names if m in results\n","            )\n","            print(line)\n","        else:\n","            print(f\"{city}: no model evaluated or all skipped\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9WRxJ8j8OQwO","executionInfo":{"status":"ok","timestamp":1747658431833,"user_tz":-60,"elapsed":786645,"user":{"displayName":"Nero Li","userId":"16312290114531733443"}},"outputId":"df90711a-b074-40e7-a8a5-c5610b8e08d0"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","===== Task: dominant_poi =====\n","Chicago: dgi 0.7959±0.1558, infograph 0.7869±0.1566, gcl 0.7908±0.1153, joao 0.7897±0.1202, simgrace 0.7971±0.1175, FractalGCL 0.7934±0.0886\n","SF: dgi 0.6476±0.1742, infograph 0.6510±0.1735, gcl 0.6686±0.1491, joao 0.6572±0.1602, simgrace 0.6690±0.1525, FractalGCL 0.6913±0.1342\n","NY: dgi 0.4849±0.1421, infograph 0.4748±0.1404, gcl 0.5057±0.1398, joao 0.4976±0.1467, simgrace 0.5027±0.1450, FractalGCL 0.5058±0.1405\n","\n","===== Task: poi_entropy_level =====\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/pandas/core/internals/blocks.py:393: RuntimeWarning: divide by zero encountered in log\n","  result = func(self.values, **kwargs)\n","/usr/local/lib/python3.11/dist-packages/numpy/lib/_function_base_impl.py:4779: RuntimeWarning: invalid value encountered in subtract\n","  diff_b_a = subtract(b, a)\n"]},{"output_type":"stream","name":"stdout","text":["Chicago: dgi 0.3588±0.0951, infograph 0.3622±0.0972, gcl 0.3883±0.1173, joao 0.3720±0.1118, simgrace 0.3847±0.1183, FractalGCL 0.4071±0.1301\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/pandas/core/internals/blocks.py:393: RuntimeWarning: divide by zero encountered in log\n","  result = func(self.values, **kwargs)\n","/usr/local/lib/python3.11/dist-packages/numpy/lib/_function_base_impl.py:4779: RuntimeWarning: invalid value encountered in subtract\n","  diff_b_a = subtract(b, a)\n"]},{"output_type":"stream","name":"stdout","text":["SF: dgi 0.4220±0.1173, infograph 0.4146±0.1169, gcl 0.4329±0.1270, joao 0.4092±0.1204, simgrace 0.4340±0.1256, FractalGCL 0.4323±0.1315\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/pandas/core/internals/blocks.py:393: RuntimeWarning: divide by zero encountered in log\n","  result = func(self.values, **kwargs)\n","/usr/local/lib/python3.11/dist-packages/numpy/lib/_function_base_impl.py:4779: RuntimeWarning: invalid value encountered in subtract\n","  diff_b_a = subtract(b, a)\n"]},{"output_type":"stream","name":"stdout","text":["NY: dgi 0.4378±0.1254, infograph 0.4432±0.1253, gcl 0.4513±0.1382, joao 0.4039±0.1293, simgrace 0.4200±0.1344, FractalGCL 0.4722±0.1374\n","\n","===== Task: pop_density_level =====\n","Chicago: dgi 0.3400±0.1015, infograph 0.3400±0.1017, gcl 0.3528±0.1137, joao 0.3451±0.1069, simgrace 0.3538±0.1102, FractalGCL 0.3659±0.1224\n","SF: dgi 0.4254±0.1338, infograph 0.4455±0.1342, gcl 0.4602±0.1374, joao 0.3965±0.1195, simgrace 0.4642±0.1367, FractalGCL 0.4671±0.1413\n","NY: dgi 0.4402±0.1311, infograph 0.4587±0.1345, gcl 0.4810±0.1395, joao 0.4389±0.1300, simgrace 0.4667±0.1392, FractalGCL 0.5083±0.1398\n","\n","===== Task: func_density_combo =====\n","Chicago: no model evaluated or all skipped\n","SF: dgi 0.4116±0.1429, infograph 0.4184±0.1428, gcl 0.4314±0.1432, joao 0.4041±0.1486, simgrace 0.4360±0.1401, FractalGCL 0.4373±0.1429\n","NY: dgi 0.3755±0.1341, infograph 0.3650±0.1357, gcl 0.3839±0.1348, joao 0.3755±0.1384, simgrace 0.3809±0.1347, FractalGCL 0.3927±0.1339\n","\n","===== Task: nightlife_hotspot =====\n","Chicago: dgi 0.5589±0.1125, infograph 0.5528±0.1053, gcl 0.5962±0.1334, joao 0.5655±0.1296, simgrace 0.5650±0.1155, FractalGCL 0.6128±0.1441\n","SF: dgi 0.4952±0.0587, infograph 0.5002±0.0662, gcl 0.4981±0.1054, joao 0.4988±0.0904, simgrace 0.5152±0.1119, FractalGCL 0.5436±0.1260\n","NY: dgi 0.5795±0.1117, infograph 0.5434±0.0976, gcl 0.5720±0.1254, joao 0.5516±0.1227, simgrace 0.5725±0.1293, FractalGCL 0.5966±0.1290\n","\n","===== Task: commercial_residential_mix =====\n","Chicago: dgi 0.3607±0.0973, infograph 0.3603±0.0981, gcl 0.3771±0.1178, joao 0.3640±0.1152, simgrace 0.3636±0.1117, FractalGCL 0.3864±0.1320\n","SF: dgi 0.4181±0.1164, infograph 0.4102±0.1133, gcl 0.4196±0.1240, joao 0.3982±0.1197, simgrace 0.4251±0.1225, FractalGCL 0.4573±0.1364\n","NY: dgi 0.3908±0.1088, infograph 0.3757±0.1028, gcl 0.3750±0.1203, joao 0.3814±0.1224, simgrace 0.3798±0.1284, FractalGCL 0.3757±0.1160\n"]}]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyPjFtL2x42cPqbl/HUVmsD2"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}